{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "공전응 팀프로젝트 12.13",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91_%ED%8C%80%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8_12_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogWeylPOt-0M",
        "colab_type": "code",
        "outputId": "d4069cba-1886-40c8-9d15-8136f32d4cf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "import shutil\n",
        "from logging import getLogger, StreamHandler, INFO\n",
        "\n",
        "\n",
        "logger = getLogger(__name__)\n",
        "logger.addHandler(StreamHandler())\n",
        "logger.setLevel(INFO)\n",
        "\n",
        "\n",
        "def install(\n",
        "        chunk_size=4096,\n",
        "        file_name=\"Miniconda3-latest-Linux-x86_64.sh\",\n",
        "        url_base=\"https://repo.continuum.io/miniconda/\",\n",
        "        conda_path=os.path.expanduser(os.path.join(\"~\", \"miniconda\")),\n",
        "        rdkit_version=None,\n",
        "        add_python_path=True,\n",
        "        force=False):\n",
        "    \"\"\"install rdkit from miniconda\n",
        "    ```\n",
        "    import rdkit_installer\n",
        "    rdkit_installer.install()\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    python_path = os.path.join(\n",
        "        conda_path,\n",
        "        \"lib\",\n",
        "        \"python{0}.{1}\".format(*sys.version_info),\n",
        "        \"site-packages\",\n",
        "    )\n",
        "\n",
        "    if add_python_path and python_path not in sys.path:\n",
        "        logger.info(\"add {} to PYTHONPATH\".format(python_path))\n",
        "        sys.path.append(python_path)\n",
        "\n",
        "    if os.path.isdir(os.path.join(python_path, \"rdkit\")):\n",
        "        logger.info(\"rdkit is already installed\")\n",
        "        if not force:\n",
        "            return\n",
        "\n",
        "        logger.info(\"force re-install\")\n",
        "\n",
        "    url = url_base + file_name\n",
        "    python_version = \"{0}.{1}.{2}\".format(*sys.version_info)\n",
        "\n",
        "    logger.info(\"python version: {}\".format(python_version))\n",
        "\n",
        "    if os.path.isdir(conda_path):\n",
        "        logger.warning(\"remove current miniconda\")\n",
        "        shutil.rmtree(conda_path)\n",
        "    elif os.path.isfile(conda_path):\n",
        "        logger.warning(\"remove {}\".format(conda_path))\n",
        "        os.remove(conda_path)\n",
        "\n",
        "    logger.info('fetching installer from {}'.format(url))\n",
        "    res = requests.get(url, stream=True)\n",
        "    res.raise_for_status()\n",
        "    with open(file_name, 'wb') as f:\n",
        "        for chunk in res.iter_content(chunk_size):\n",
        "            f.write(chunk)\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info('installing miniconda to {}'.format(conda_path))\n",
        "    subprocess.check_call([\"bash\", file_name, \"-b\", \"-p\", conda_path])\n",
        "    logger.info('done')\n",
        "\n",
        "    logger.info(\"installing rdkit\")\n",
        "    subprocess.check_call([\n",
        "        os.path.join(conda_path, \"bin\", \"conda\"),\n",
        "        \"install\",\n",
        "        \"--yes\",\n",
        "        \"-c\", \"rdkit\",\n",
        "        \"python=={}\".format(python_version),\n",
        "        \"rdkit\" if rdkit_version is None else \"rdkit=={}\".format(rdkit_version)])\n",
        "    logger.info(\"done\")\n",
        "\n",
        "    import rdkit\n",
        "    logger.info(\"rdkit-{} installation finished!\".format(rdkit.__version__))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    install()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "add /root/miniconda/lib/python3.6/site-packages to PYTHONPATH\n",
            "rdkit is already installed\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bABZQrH6vOv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "from rdkit.Chem import Draw"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCpJ-2nrvhzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# General Imports\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, Descriptors\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFSGBUquvwh9",
        "colab_type": "code",
        "outputId": "a7dc139b-d200-4af9-f440-7409c5ea4ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "smifile = \"gdb11_size08.smi\"\n",
        "data = pd.read_csv('/content/gdb11_size08.smi', delimiter = \"\\t\", names = [\"smiles\",\"No\",\"Int\"])\n",
        "from sklearn.model_selection import train_test_split\n",
        "smiles_train, smiles_test = train_test_split(data[\"smiles\"], random_state=42)\n",
        "print(smiles_train.shape)\n",
        "print(smiles_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50029,)\n",
            "(16677,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5ODezm_vyhm",
        "colab_type": "code",
        "outputId": "8562a97f-79ea-42d2-bc0d-2ae9c7d00aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "charset = set(\"\".join(list(data.smiles))+\"!E\")\n",
        "char_to_int = dict((c,i) for i,c in enumerate(charset))\n",
        "int_to_char = dict((i,c) for i,c in enumerate(charset))\n",
        "embed = max([len(smile) for smile in data.smiles]) + 5\n",
        "print(str(charset))\n",
        "print(len(charset), embed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'-', ')', '[', '2', 'n', 'H', '+', 'o', '1', 'c', 'F', 'C', 'E', '=', 'O', 'N', '4', '(', ']', '!', '3', '#'}\n",
            "22 28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwi4e77uyYQQ",
        "colab_type": "code",
        "outputId": "b6a2abde-6db3-4938-db8b-88326bea1b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        }
      },
      "source": [
        "def vectorize(smiles):\n",
        "        one_hot =  np.zeros((smiles.shape[0], embed , len(charset)),dtype=np.int8)\n",
        "        for i,smile in enumerate(smiles):\n",
        "            #encode the startchar\n",
        "            one_hot[i,0,char_to_int[\"!\"]] = 1\n",
        "            #encode the rest of the chars\n",
        "            for j,c in enumerate(smile):\n",
        "                one_hot[i,j+1,char_to_int[c]] = 1\n",
        "            #Encode endchar\n",
        "            one_hot[i,len(smile)+1:,char_to_int[\"E\"]] = 1\n",
        "        #Return two, one for input and the other for output\n",
        "        return one_hot[:,0:-1,:], one_hot[:,1:,:]\n",
        "X_train, Y_train = vectorize(smiles_train.values)\n",
        "X_test,Y_test = vectorize(smiles_test.values)\n",
        "print(smiles_train.iloc[0])\n",
        "plt.matshow(X_train[0].T)\n",
        "#print X_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N#CC#CC1COC1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f10cf59c748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATQAAAECCAYAAABwoisvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkubCoElqw6BJasOgSWrDoElq438BK63yFeRPO50AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 353.455x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NK1-FHPj15Zr",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq8QiTGtybqC",
        "colab_type": "code",
        "outputId": "493cc88e-86aa-4261-f2e0-17528c35d7e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "\"\".join([int_to_char[idx] for idx in np.argmax(X_train[0,:,:], axis=1)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!N#CC#CC1COC1EEEEEEEEEEEEEE'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svpfaaqPy44j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "\n",
        "    %tensorflow_version 1.x  \n",
        "\n",
        "except Exception:\n",
        "\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HXjnPw_ywkw",
        "colab_type": "code",
        "outputId": "3895c221-a8ee-41e9-c18f-7481633c9748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Import Keras objects\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Concatenate\n",
        "from keras import regularizers\n",
        "input_shape = X_train.shape[1:]\n",
        "output_dim = Y_train.shape[-1]\n",
        "latent_dim = 64\n",
        "lstm_dim = 64"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n64wGkhFy0g4",
        "colab_type": "code",
        "outputId": "bf630326-0df1-4dfb-9327-bdb0d7932f61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "source": [
        "unroll = False\n",
        "encoder_inputs = Input(shape=input_shape)\n",
        "encoder = LSTM(lstm_dim, return_state=True,\n",
        "                unroll=unroll)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "states = Concatenate(axis=-1)([state_h, state_c])\n",
        "neck = Dense(latent_dim, activation=\"relu\")\n",
        "neck_outputs = neck(states)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1w5JZl2zTDQ",
        "colab_type": "code",
        "outputId": "bd2df56d-76b4-4edb-d14b-ef415474094a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "decode_h = Dense(lstm_dim, activation=\"relu\")\n",
        "decode_c = Dense(lstm_dim, activation=\"relu\")\n",
        "state_h_decoded =  decode_h(neck_outputs)\n",
        "state_c_decoded =  decode_c(neck_outputs)\n",
        "encoder_states = [state_h_decoded, state_c_decoded]\n",
        "decoder_inputs = Input(shape=input_shape)\n",
        "decoder_lstm = LSTM(lstm_dim,\n",
        "                    return_sequences=True,\n",
        "                    unroll=unroll\n",
        "                   )\n",
        "decoder_outputs = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = Dense(output_dim, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "#Define the model, that inputs the training vector for two places, and predicts one character ahead of the input\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 27, 22)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 64), (None,  22272       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128)          0           lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           8256        concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 27, 22)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 64)           4160        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 27, 64)       22272       input_2[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 27, 22)       1430        lstm_2[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 62,550\n",
            "Trainable params: 62,550\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dvqLPm60gF6",
        "colab_type": "code",
        "outputId": "34758c2f-ff79-4f66-9099-f7e7c1c261b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from keras.callbacks import History, ReduceLROnPlateau\n",
        "h = History()\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.000001, verbose=1, epsilon=1e-5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1335: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJVpIA-F0jvf",
        "colab_type": "code",
        "outputId": "50730e3c-b6eb-4297-8137-857608c62a00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.optimizers import RMSprop, Adam #Default 0.001\n",
        "model.compile( optimizer='Adam', loss='categorical_crossentropy')\n",
        "model.fit([X_train,X_train],Y_train,\n",
        "                    epochs=200,\n",
        "                    batch_size=256,\n",
        "                    shuffle=True,\n",
        "                    callbacks=[h, rlr],\n",
        "                    validation_data=[[X_test,X_test],Y_test ])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 50029 samples, validate on 16677 samples\n",
            "Epoch 1/200\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "50029/50029 [==============================] - 18s 359us/step - loss: 1.2067 - val_loss: 0.8984\n",
            "Epoch 2/200\n",
            "50029/50029 [==============================] - 16s 321us/step - loss: 0.8149 - val_loss: 0.7336\n",
            "Epoch 3/200\n",
            "50029/50029 [==============================] - 16s 322us/step - loss: 0.6765 - val_loss: 0.6234\n",
            "Epoch 4/200\n",
            "50029/50029 [==============================] - 16s 330us/step - loss: 0.5980 - val_loss: 0.5787\n",
            "Epoch 5/200\n",
            "50029/50029 [==============================] - 16s 322us/step - loss: 0.5644 - val_loss: 0.5386\n",
            "Epoch 6/200\n",
            "50029/50029 [==============================] - 16s 325us/step - loss: 0.5268 - val_loss: 0.5102\n",
            "Epoch 7/200\n",
            "50029/50029 [==============================] - 16s 323us/step - loss: 0.4974 - val_loss: 0.5097\n",
            "Epoch 8/200\n",
            "50029/50029 [==============================] - 16s 326us/step - loss: 0.4762 - val_loss: 0.4699\n",
            "Epoch 9/200\n",
            "50029/50029 [==============================] - 16s 324us/step - loss: 0.4580 - val_loss: 0.4496\n",
            "Epoch 10/200\n",
            "50029/50029 [==============================] - 16s 324us/step - loss: 0.4362 - val_loss: 0.4244\n",
            "Epoch 11/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.4255 - val_loss: 0.4067\n",
            "Epoch 12/200\n",
            "50029/50029 [==============================] - 16s 321us/step - loss: 0.4162 - val_loss: 0.4028\n",
            "Epoch 13/200\n",
            "50029/50029 [==============================] - 16s 321us/step - loss: 0.3990 - val_loss: 0.3824\n",
            "Epoch 14/200\n",
            "50029/50029 [==============================] - 16s 325us/step - loss: 0.3943 - val_loss: 0.3980\n",
            "Epoch 15/200\n",
            "50029/50029 [==============================] - 16s 321us/step - loss: 0.3766 - val_loss: 0.3669\n",
            "Epoch 16/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.3638 - val_loss: 0.3443\n",
            "Epoch 17/200\n",
            "50029/50029 [==============================] - 16s 322us/step - loss: 0.3474 - val_loss: 0.3256\n",
            "Epoch 18/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.3390 - val_loss: 0.3458\n",
            "Epoch 19/200\n",
            "50029/50029 [==============================] - 16s 322us/step - loss: 0.3313 - val_loss: 0.3349\n",
            "Epoch 20/200\n",
            "50029/50029 [==============================] - 16s 322us/step - loss: 0.3172 - val_loss: 0.3287\n",
            "Epoch 21/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.3086 - val_loss: 0.2921\n",
            "Epoch 22/200\n",
            "50029/50029 [==============================] - 16s 319us/step - loss: 0.3005 - val_loss: 0.2916\n",
            "Epoch 23/200\n",
            "50029/50029 [==============================] - 16s 324us/step - loss: 0.2947 - val_loss: 0.2809\n",
            "Epoch 24/200\n",
            "50029/50029 [==============================] - 16s 323us/step - loss: 0.2826 - val_loss: 0.2738\n",
            "Epoch 25/200\n",
            "50029/50029 [==============================] - 16s 318us/step - loss: 0.2786 - val_loss: 0.2579\n",
            "Epoch 26/200\n",
            "50029/50029 [==============================] - 16s 318us/step - loss: 0.2743 - val_loss: 0.2571\n",
            "Epoch 27/200\n",
            "50029/50029 [==============================] - 16s 318us/step - loss: 0.2616 - val_loss: 0.2421\n",
            "Epoch 28/200\n",
            "50029/50029 [==============================] - 16s 325us/step - loss: 0.2500 - val_loss: 0.2450\n",
            "Epoch 29/200\n",
            "50029/50029 [==============================] - 16s 328us/step - loss: 0.2415 - val_loss: 0.2250\n",
            "Epoch 30/200\n",
            "50029/50029 [==============================] - 16s 325us/step - loss: 0.2367 - val_loss: 0.2400\n",
            "Epoch 31/200\n",
            "50029/50029 [==============================] - 16s 324us/step - loss: 0.2273 - val_loss: 0.2409\n",
            "Epoch 32/200\n",
            "50029/50029 [==============================] - 16s 323us/step - loss: 0.2195 - val_loss: 0.1970\n",
            "Epoch 33/200\n",
            "50029/50029 [==============================] - 17s 335us/step - loss: 0.2172 - val_loss: 0.2025\n",
            "Epoch 34/200\n",
            "50029/50029 [==============================] - 16s 326us/step - loss: 0.2027 - val_loss: 0.2083\n",
            "Epoch 35/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.2048 - val_loss: 0.1887\n",
            "Epoch 36/200\n",
            "50029/50029 [==============================] - 16s 319us/step - loss: 0.1897 - val_loss: 0.1779\n",
            "Epoch 37/200\n",
            "50029/50029 [==============================] - 16s 324us/step - loss: 0.1889 - val_loss: 0.1855\n",
            "Epoch 38/200\n",
            "50029/50029 [==============================] - 16s 325us/step - loss: 0.1995 - val_loss: 0.2079\n",
            "Epoch 39/200\n",
            "50029/50029 [==============================] - 17s 334us/step - loss: 0.1880 - val_loss: 0.1610\n",
            "Epoch 40/200\n",
            "50029/50029 [==============================] - 16s 321us/step - loss: 0.1684 - val_loss: 0.1894\n",
            "Epoch 41/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.1627 - val_loss: 0.2465\n",
            "Epoch 42/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.1717 - val_loss: 0.1532\n",
            "Epoch 43/200\n",
            "50029/50029 [==============================] - 16s 322us/step - loss: 0.1541 - val_loss: 0.1498\n",
            "Epoch 44/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.1481 - val_loss: 0.2157\n",
            "Epoch 45/200\n",
            "50029/50029 [==============================] - 16s 318us/step - loss: 0.1521 - val_loss: 0.2173\n",
            "Epoch 46/200\n",
            "50029/50029 [==============================] - 16s 319us/step - loss: 0.1890 - val_loss: 0.1284\n",
            "Epoch 47/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.1365 - val_loss: 0.1283\n",
            "Epoch 48/200\n",
            "50029/50029 [==============================] - 16s 318us/step - loss: 0.1310 - val_loss: 0.1242\n",
            "Epoch 49/200\n",
            "50029/50029 [==============================] - 16s 321us/step - loss: 0.1288 - val_loss: 0.1139\n",
            "Epoch 50/200\n",
            "50029/50029 [==============================] - 16s 317us/step - loss: 0.1252 - val_loss: 0.1146\n",
            "Epoch 51/200\n",
            "50029/50029 [==============================] - 16s 321us/step - loss: 0.1233 - val_loss: 0.1106\n",
            "Epoch 52/200\n",
            "50029/50029 [==============================] - 16s 320us/step - loss: 0.1161 - val_loss: 0.1232\n",
            "Epoch 53/200\n",
            "50029/50029 [==============================] - 16s 319us/step - loss: 0.1484 - val_loss: 0.1246\n",
            "Epoch 54/200\n",
            "50029/50029 [==============================] - 16s 319us/step - loss: 0.1126 - val_loss: 0.1095\n",
            "Epoch 55/200\n",
            "50029/50029 [==============================] - 16s 317us/step - loss: 0.1142 - val_loss: 0.1061\n",
            "Epoch 56/200\n",
            "50029/50029 [==============================] - 16s 317us/step - loss: 0.1065 - val_loss: 0.0970\n",
            "Epoch 57/200\n",
            "50029/50029 [==============================] - 16s 318us/step - loss: 0.1040 - val_loss: 0.0956\n",
            "Epoch 58/200\n",
            "50029/50029 [==============================] - 16s 316us/step - loss: 0.1509 - val_loss: 0.0930\n",
            "Epoch 59/200\n",
            "50029/50029 [==============================] - 16s 317us/step - loss: 0.1077 - val_loss: 0.0837\n",
            "Epoch 60/200\n",
            "50029/50029 [==============================] - 16s 317us/step - loss: 0.1046 - val_loss: 0.0823\n",
            "Epoch 61/200\n",
            "50029/50029 [==============================] - 16s 316us/step - loss: 0.1062 - val_loss: 0.0890\n",
            "Epoch 62/200\n",
            "50029/50029 [==============================] - 16s 323us/step - loss: 0.0895 - val_loss: 0.0808\n",
            "Epoch 63/200\n",
            "50029/50029 [==============================] - 16s 316us/step - loss: 0.1128 - val_loss: 0.0916\n",
            "Epoch 64/200\n",
            "16896/50029 [=========>....................] - ETA: 9s - loss: 0.0847"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec5V9OiLpgU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(h.history[\"loss\"], label=\"Loss\")\n",
        "plt.plot(h.history[\"val_loss\"], label=\"Val_Loss\")\n",
        "plt.yscale(\"log\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsq37RILb9b9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(100):\n",
        "    v = model.predict([X_test[i:i+1], X_test[i:i+1]]) #Can't be done as output not necessarely 1\n",
        "    idxs = np.argmax(v, axis=2)\n",
        "    pred=  \"\".join([int_to_char[h] for h in idxs[0]])[:-1]\n",
        "    idxs2 = np.argmax(X_test[i:i+1], axis=2)\n",
        "    true =  \"\".join([int_to_char[k] for k in idxs2[0]])[1:]\n",
        "    if true != pred:\n",
        "      print (true, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHgHkD82doHj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smiles_to_latent_model = Model(encoder_inputs, neck_outputs)\n",
        "smiles_to_latent_model.save(\"Blog_simple_smi2lat.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8SHndPNe1tc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "latent_input = Input(shape=(latent_dim,))\n",
        "#reuse_layers\n",
        "state_h_decoded_2 =  decode_h(latent_input)\n",
        "state_c_decoded_2 =  decode_c(latent_input)\n",
        "latent_to_states_model = Model(latent_input, [state_h_decoded_2, state_c_decoded_2])\n",
        "latent_to_states_model.save(\"Blog_simple_lat2state.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LM2RvUHe53r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Last one is special, we need to change it to stateful, and change the input shape\n",
        "inf_decoder_inputs = Input(batch_shape=(1, 1, input_shape[1]))\n",
        "inf_decoder_lstm = LSTM(lstm_dim,\n",
        "                    return_sequences=True,\n",
        "                    unroll=unroll,\n",
        "                    stateful=True\n",
        "                   )\n",
        "inf_decoder_outputs = inf_decoder_lstm(inf_decoder_inputs)\n",
        "inf_decoder_dense = Dense(output_dim, activation='softmax')\n",
        "inf_decoder_outputs = inf_decoder_dense(inf_decoder_outputs)\n",
        "sample_model = Model(inf_decoder_inputs, inf_decoder_outputs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pET58amIe8wS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Transfer Weights\n",
        "for i in range(1,3):\n",
        "    sample_model.layers[i].set_weights(model.layers[i+6].get_weights())\n",
        "sample_model.save(\"Blog_simple_samplemodel.h5\")\n",
        "1\n",
        "sample_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIK7fPBre_8q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_latent = smiles_to_latent_model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQMmrCZTfBh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "molno = 5\n",
        "latent_mol = smiles_to_latent_model.predict(X_test[molno:molno+1])\n",
        "sorti = np.argsort(np.sum(np.abs(x_latent - latent_mol), axis=1))\n",
        "print (sorti[0:10])\n",
        "print (smiles_test.iloc[sorti[0:8]])\n",
        "Draw.MolsToImage(smiles_test.iloc[sorti[0:8]].apply(Chem.MolFromSmiles))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37uw0ta2fEIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Draw.MolsToImage(smiles_test.iloc[sorti[-8:]].apply(Chem.MolFromSmiles))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhlae9GgfPMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logp = smiles_test.apply(Chem.MolFromSmiles).apply(Descriptors.MolLogP)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components = 2)\n",
        "red = pca.fit_transform(x_latent)\n",
        "plt.figure()\n",
        "plt.scatter(red[:,0], red[:,1],marker='.', c= logp)\n",
        "print(pca.explained_variance_ratio_, np.sum(pca.explained_variance_ratio_))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sAn-N18fSir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "molwt = smiles_test.apply(Chem.MolFromSmiles).apply(Descriptors.MolMR)\n",
        "plt.figure()\n",
        "plt.scatter(red[:,0], red[:,1],marker='.', c= molwt)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMlEd4PQfVjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model LogP?\n",
        "x_train_latent = smiles_to_latent_model.predict(X_train)\n",
        "logp_train = smiles_train.apply(Chem.MolFromSmiles).apply(Descriptors.MolLogP)\n",
        "\n",
        "from keras.models import Sequential\n",
        "logp_model = Sequential()\n",
        "logp_model.add(Dense(128, input_shape=(latent_dim,), activation=\"relu\"))\n",
        "logp_model.add(Dense(128, activation=\"relu\"))\n",
        "logp_model.add(Dense(1))\n",
        "logp_model.compile(optimizer=\"adam\", loss=\"mse\")\n",
        "\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,patience=10, min_lr=0.000001, verbose=1, epsilon=1e-5)\n",
        "logp_model.fit(x_train_latent, logp_train, batch_size=128, epochs=400, callbacks = [rlr])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZ1W9CSCfa6j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logp_pred_train = logp_model.predict(x_train_latent)\n",
        "logp_pred_test = logp_model.predict(x_latent)\n",
        "plt.scatter(logp, logp_pred_test, label=\"Test\")\n",
        "plt.scatter(logp_train, logp_pred_train, label=\"Train\")\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcifE6iaiuJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def latent_to_smiles(latent):\n",
        "    #decode states and set Reset the LSTM cells with them\n",
        "    states = latent_to_states_model.predict(latent)\n",
        "    sample_model.layers[1].reset_states(states=[states[0],states[1]])\n",
        "    #Prepare the input char\n",
        "    startidx = char_to_int[\"!\"]\n",
        "    samplevec = np.zeros((1,1,22))\n",
        "    samplevec[0,0,startidx] = 1\n",
        "    smiles = \"\"\n",
        "    #Loop and predict next char\n",
        "    for i in range(28):\n",
        "        o = sample_model.predict(samplevec)\n",
        "        sampleidx = np.argmax(o)\n",
        "        samplechar = int_to_char[sampleidx]\n",
        "        if samplechar != \"E\":\n",
        "            smiles = smiles + int_to_char[sampleidx]\n",
        "            samplevec = np.zeros((1,1,22))\n",
        "            samplevec[0,0,sampleidx] = 1\n",
        "        else:\n",
        "            break\n",
        "    return smiles"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4aDG6UEiw-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "smiles = latent_to_smiles(x_latent[0:1])\n",
        "print (smiles)\n",
        "print (smiles_test.iloc[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSaU_M6tiyVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wrong = 0\n",
        "for i in range(1000):\n",
        "    smiles = latent_to_smiles(x_latent[i:i+1])\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol:\n",
        "        pass\n",
        "    else:\n",
        "        print (smiles)\n",
        "        wrong = wrong + 1\n",
        "print (\"%0.1F percent wrongly formatted smiles\"%(wrong/float(1000)*100))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HyzkEL_i2A7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Interpolation test in latent_space\n",
        "i = 0\n",
        "j= 2\n",
        "latent1 = x_latent[j:j+1]\n",
        "latent0 = x_latent[i:i+1]\n",
        "mols1 = []\n",
        "ratios = np.linspace(0,1,25)\n",
        "for r in ratios:\n",
        "    #print r\n",
        "    rlatent = (1.0-r)*latent0 + r*latent1\n",
        "    smiles  = latent_to_smiles(rlatent)\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol:\n",
        "        mols1.append(mol)\n",
        "    else:\n",
        "        print (smiles)\n",
        "Draw.MolsToGridImage(mols1, molsPerRow=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Myn7kbEgmHLf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Sample around the latent wector\n",
        "latent = x_latent[0:1]\n",
        "scale = 0.40\n",
        "mols = []\n",
        "for i in range(20):\n",
        "    latent_r = latent + scale*(np.random.randn(latent.shape[1])) #TODO, try with\n",
        "    smiles = latent_to_smiles(latent_r)\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol:\n",
        "        mols.append(mol)\n",
        "    else:\n",
        "        print (smiles)\n",
        "Draw.MolsToGridImage(mols, molsPerRow=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7vgc_sQmRbL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}