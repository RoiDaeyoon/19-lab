{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN-Keras",
      "provenance": [],
      "authorship_tag": "ABX9TyMGIYLyu81g10wdaUsRkzDX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinhs0920/19-lab/blob/master/GAN_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMMK0-ZkQxd4",
        "colab_type": "text"
      },
      "source": [
        "# 생성적 적대 신경망(**GAN**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaSDr6pBRObl",
        "colab_type": "text"
      },
      "source": [
        "### 개요"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyJdsrnsQ6My",
        "colab_type": "text"
      },
      "source": [
        "GAN은 **생성기**와 **판별기**라는 두 네트워크로 구성된다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_zQPdg_RQXX",
        "colab_type": "text"
      },
      "source": [
        "**생성기**의 역할 : 판별기를 속일 수 있는 위조 데이터(가짜 데이터)를 계속 생성한다.\n",
        "<BR>**판별기**의 역할 : 생성기로부터 받은 **위조 데이터**와 실제 샘플 데이터에서 받은 **실제 데이터**를 구분한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccJz0nenQ6iv",
        "colab_type": "text"
      },
      "source": [
        "생성기의 입력은 노이즈이며, 출력은 합성된 가짜 신호이다.\n",
        "<BR>판별기의 입력은 진짜 신호 혹은 생성기의 출력인 가짜 신호(합성 신호)이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAK1eIk2R5V0",
        "colab_type": "text"
      },
      "source": [
        "유효 신호의 레이블은 1.0(즉, 진짜 데이터)이며, 합성된 신호의 레이블은 모두 0.0이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cQz9df1SAM4",
        "colab_type": "text"
      },
      "source": [
        "### GAN 모델 데이터 처리 과정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u85OOBaNQ6n7",
        "colab_type": "text"
      },
      "source": [
        "자기가 만든 출력이 진짜 데이터인 척하며 GAN에게 자기의 출력에 1.0으로 레이블을 붙일 것을 요청한다. 그리고 1.0으로 레이블 붙여진 가짜 데이터를 판별기에게 보이면 판별기에 의해 그 데이터는 레이블이 0.0에 가까워지며 가짜 신호로 분류된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvWfj2AkQ6wP",
        "colab_type": "text"
      },
      "source": [
        "또한 판별기는 새로운 데이터 훈련 시, 자신이 예측한 값을 포함하기에 GAN은 오차값을 염두해 둔다.이 경사를 판별기의 마지막 층에서 생성기의 첫 번째 층으로 역전파시킨다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSl9PJNuQ61q",
        "colab_type": "text"
      },
      "source": [
        "## 심층 합성곱 GAN(DCGAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3_tVtAVQ66U",
        "colab_type": "text"
      },
      "source": [
        "-> 초기에 심층 CNN을 사용해 GAN을 구현한 모델 (가짜 이미지를 생성하기 위해 사용된다.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF2e_szjQ6-4",
        "colab_type": "text"
      },
      "source": [
        "### 모델 설계 시 차이점"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgmaeZNEQ7Dh",
        "colab_type": "text"
      },
      "source": [
        "- MaxPooling2D 대신 strides>1 합성곱을 사용한다. CNN이 특징 맵 크기를 조절하는 법을 학습한다.\n",
        "\n",
        "- Dense 계층은 생성기의 첫번째 계층에서 z-vector를 받기 위해 사용된다. \n",
        "\n",
        "- 각 계층의 입력이 평균 0의 분산을 가지기 위해 배치 정규화(BN)을 사용한다.\n",
        "\n",
        "- 판별기 전 계층에 Leaky ReLU를 사용한다. 이는 ReLU와 달리 $alpha\\times input $처럼 작은 경사 값을 생성하는 함수이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eS4MdcEQ7Ih",
        "colab_type": "text"
      },
      "source": [
        "### 모델 구성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIsRlReQQ7O-",
        "colab_type": "text"
      },
      "source": [
        "생성기는 -1.0에서 1.0 사이에서 생성된 100차원 z-벡터를 받는다. 첫번째 계층은 $7\\times 7\\times 128=6,272$개의 유닛을 가진 Dense 계층이다. 유닛 개수는 최종 출력 이미지의 차원 ($28\\times 28\\times 1$, 28은 7의 배수)과 첫 번째 Conv2DTranspose의 필터 개수 128을 기준으로 한다.\n",
        "\n",
        "- Conv2DTranspose : Conv2D의 전치이며, 특징 맵에서 이미지를 생산한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX_ExyvyQ7Te",
        "colab_type": "text"
      },
      "source": [
        "두 번의 Conv2DTranspose 계층을 거치면 특징 맵 크기는 $28\\times 28\\times$ '필터 갯수'이다. 마지막 계층에는 가짜 이미지를 생성하는 시그모이드 함수가 있다. <br>각 픽셀은 [0,255]의 회색조 레이블에 대응하는 [0.0, 1.0]으로 정규화 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdl18zb0nC6_",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4VtOiupnknM",
        "colab_type": "code",
        "outputId": "21120780-0817-4930-80d1-d1fd0262b132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "# 1. 생성기 모델 구성\n",
        "def build_generator(inputs, image_size):\n",
        " # 가짜 이미지를 만들기 위해 BN-ReLU-Conv2DTranpose 으로 구성. 출력층 활성화 함수는 tanh 대신 Sigmoid 사용 - Sigmoid가 더 수렴이 쉬움\n",
        " # 두개의 층을 각각 지나면서 크기가 절반씩 줄어드므로 총 크기는 1/4 이 된다   \n",
        "    image_resize = image_size // 4\n",
        "\n",
        "   \n",
        "# 네트워크 매개변수\n",
        "    kernel_size = 5\n",
        "    layer_filters = [128, 64, 32, 1]\n",
        "\n",
        "    x = Dense(image_resize * image_resize * layer_filters[0])(inputs)\n",
        "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
        "\n",
        "    for filters in layer_filters:\n",
        "         # 첫 두 합성곱 계층이 strides = 2 사용\n",
        "        # 마지막 두 계층은 strides = 1 사용\n",
        "        if filters > layer_filters[-2]:\n",
        "            strides = 2\n",
        "        else:\n",
        "            strides = 1\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=filters,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same')(x)\n",
        "\n",
        "    x = Activation('sigmoid')(x)\n",
        "    generator = Model(inputs, x, name='generator')\n",
        "    return generator\n",
        "\n",
        "# 2. 판별기 모델 구성\n",
        "def build_discriminator(inputs):\n",
        "     # 진짜와 가짜를 구분하기 위해 LeakyReLU-Conv2D 구조 사용. 배치 정규화로는 수렴하지 않으므로 사용하지 않음.\n",
        "\n",
        "    kernel_size = 5\n",
        "    layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "    x = inputs\n",
        "    for filters in layer_filters:\n",
        "          # 첫 3개의 합성곱 계층은 strides = 2 사용.\n",
        "        # 마지막 계층은 strides = 1 사용.\n",
        "        if filters == layer_filters[-1]:\n",
        "            strides = 1\n",
        "        else:\n",
        "            strides = 2\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Conv2D(filters=filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   strides=strides,\n",
        "                   padding='same')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    discriminator = Model(inputs, x, name='discriminator')\n",
        "    return discriminator\n",
        "\n",
        "# 5. 판별기와 적대적 네트워크 훈련\n",
        "\n",
        "def train(models, x_train, params):\n",
        " # 판별기는 진짜와 가짜 이미지를 가지고 훈련되며, 그 후 적대적 네트워크는 진짜인 척 하는 가짜 이미지로 훈련된다\n",
        "    # GAN 모델  \n",
        "    generator, discriminator, adversarial = models\n",
        "\n",
        "   # 네트워크 파라미터\n",
        "    batch_size, latent_size, train_steps, model_name = params\n",
        "    \n",
        "   # 500단계마다 생성기 이미지가 저장된다.\n",
        "    save_interval = 500\n",
        "   # 노이즈 벡터 - 훈련 기간 동안 생성기 출력 이미지 변화 관찰 위한 벡터\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
        "   \n",
        "    train_size = x_train.shape[0]\n",
        "    for i in range(train_steps):\n",
        "        # 1배치에 대한 판별기 훈련\n",
        "        # 1배치 = 진짜(label=1.0)와 가짜 이미지(label=0.0)로 구성된 배치\n",
        "        # 데이터 세트에서 임의로 진짜 이미지 선택\n",
        "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
        "        real_images = x_train[rand_indexes]\n",
        "       \n",
        "        noise = np.random.uniform(-1.0,\n",
        "                                  1.0,\n",
        "                                  size=[batch_size, latent_size])\n",
        "        # 가짜 이미지 생성\n",
        "        fake_images = generator.predict(noise)\n",
        "\n",
        "        # 진짜 + 가짜 이미지 = 훈련 데이터의 1 배치\n",
        "        x = np.concatenate((real_images, fake_images))\n",
        "\n",
        "        # 진짜와 가짜 이미지에 레이블을 붙인다. 진짜는 1.0\n",
        "        y = np.ones([2 * batch_size, 1])\n",
        "\n",
        "        # 가짜는 0.0\n",
        "        y[batch_size:, :] = 0.0\n",
        "\n",
        "        # 판별기 네트워크 훈련, 손실과 정확도 기록\n",
        "        loss, acc = discriminator.train_on_batch(x, y)\n",
        "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
        "\n",
        " # 6. 1 배치에 대한 적대적 네트워크 훈련\n",
        "        # label=1.0인 가짜 이미지로 구성된 1배치\n",
        "        # 적대적 네트워크에서 판별기 가중치가 고정되므로 생성기만 훈련된다.\n",
        "    \n",
        "        noise = np.random.uniform(-1.0,\n",
        "                                  1.0, \n",
        "                                  size=[batch_size, latent_size])\n",
        "        y = np.ones([batch_size, 1])\n",
        "        # 적대적 네트워크 훈련 \n",
        "        # 가짜 이미지는 분류를 위해 적대적 네트워크의 판별기 입력으로 전달된다.\n",
        "        # 손실, 정확도 기록\n",
        "        loss, acc = adversarial.train_on_batch(noise, y)\n",
        "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
        "        print(log)\n",
        "        if (i + 1) % save_interval == 0:\n",
        "            plot_images(generator,\n",
        "                        noise_input=noise_input,\n",
        "                        show=False,\n",
        "                        step=(i + 1),\n",
        "                        model_name=model_name)\n",
        "   \n",
        "    generator.save(model_name + \".h5\")\n",
        "    \n",
        "# 3. 훈련\n",
        "def build_and_train_models():\n",
        "    (x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "    # CNN을 위해 (28, 28, 1) 로 데이터 형상 구현 및 정규화\n",
        "image_size = x_train.shape[1]\n",
        "x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "x_train = x_train.astype('float32') / 255\n",
        "\n",
        "model_name = \"dcgan_mnist\"\n",
        "    \n",
        "latent_size = 100 # z-vector는 100차원 벡터\n",
        "batch_size = 64\n",
        "train_steps = 40000\n",
        "lr = 2e-4\n",
        "decay = 6e-8\n",
        "input_shape = (image_size, image_size, 1)\n",
        "\n",
        "    # 판별기 모델 구성\n",
        "inputs = Input(shape=input_shape, name='discriminator_input')\n",
        "discriminator = build_discriminator(inputs)\n",
        "  \n",
        "    # RMSprop로 최적화 - 쉽게 수렴한다.\n",
        "optimizer = RMSprop(lr=lr, decay=decay)\n",
        "discriminator.compile(loss='binary_crossentropy',\n",
        "                        optimizer=optimizer,\n",
        "                          metrics=['accuracy'])\n",
        "discriminator.summary()\n",
        "\n",
        "    # 생성기 모델 구성\n",
        "input_shape = (latent_size, )\n",
        "inputs = Input(shape=input_shape, name='z_input')\n",
        "generator = build_generator(inputs, image_size)\n",
        "generator.summary()\n",
        "\n",
        "    # 적대적 모델 구성\n",
        "optimizer = RMSprop(lr=lr * 0.5, decay=decay * 0.5)\n",
        "  \n",
        "    # 적대적 모델 훈련 과정 동안 판별기 가중치 고정\n",
        "discriminator.trainable = False\n",
        "\n",
        "    # adversarial = generator + discriminator (생성기 판별기 결합)\n",
        "adversarial = Model(inputs, \n",
        "                        discriminator(generator(inputs)),\n",
        "                        name=model_name)\n",
        "adversarial.compile(loss='binary_crossentropy',\n",
        "                        optimizer=optimizer,\n",
        "                        metrics=['accuracy'])\n",
        "adversarial.summary()\n",
        "\n",
        "    # 생성기와 판별기 네트워크 훈련\n",
        "models = (generator, discriminator, adversarial)\n",
        "params = (batch_size, latent_size, train_steps, model_name)\n",
        "train(models, x_train, params)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-912ced33dad3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;31m# CNN을 위해 (28, 28, 1) 로 데이터 형상 구현 및 정규화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0mimage_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUu1x0WTQ7ck",
        "colab_type": "text"
      },
      "source": [
        "판별기의 입력은 $28\\times 28\\times 1$ MNIST 이미지이며, 진짜(1.0) 혹은 가짜(0.0)으로 분류된다. 또한 판별기는 4개의 CNN 계층을 갖는다. 또한 최종 출력 계층은 일차원으로 변환되어 시그모이드함수를 거쳐 0.0~1.0 사이 값으로 예측을 생성한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UohSYIe5Q7hS",
        "colab_type": "text"
      },
      "source": [
        "이렇게 생성기와 판별기 계층을 구성한 뒤 둘을 결합해 적대적 모델을 구성한다.\n",
        "적대적 모델의 최적화는 RMSprop 최적화를 사용한다. 적대적 신경망의 학습 속도를 판별기 학습 속도의 반으로 설정하면 더 안정적으로 훈련할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGj8qfVPQ7nH",
        "colab_type": "text"
      },
      "source": [
        "생성기는 적대적 네트워크를 통해 훈련된다. 먼저 임의로 데이터 세트에서 실제 이미지로 구성된 배치를 선택하여 1.0 레이블을 붙이며, 생성기에서 가짜 이미지로 구성된 배치가 생성된다. 이는 0.0 레이블이 붙으며 이 두 배치를 연결하여 판별기 훈련에 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq1SML6DQ7sQ",
        "colab_type": "text"
      },
      "source": [
        "위 과정이 완료되면 생성기가 새로운 가짜 이미지 배치를 생성하고 거기에 진짜 레이블인 1.0을 붙여 적대적 네트워크를 훈련시키기 위해 사용한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN33KT7PQ7xx",
        "colab_type": "text"
      },
      "source": [
        "## 조건부 GAN (CGAN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2WnzVJuoWpf",
        "colab_type": "text"
      },
      "source": [
        "DCGAN에서 가짜 이미지는 임의로 생성된다. 생성기에서 어떤 숫자를 생성할지 우리가 제어할 수 없다. 이 문제를 보완한 것이 조건부 GAN이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XltoAw6mQ78E",
        "colab_type": "text"
      },
      "source": [
        "동일한 GAN을 사용하지만 생성기와 판별기 입력 모두에 조건을 부여한다. 그 조건은 입력을 원-핫 벡터 형태로 변환하는 것이다. DCGAN과의 차이점은 입력으로 원-핫 벡터를 추가로 받는 것이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwc7X4brQ8BM",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOSOzsOXqOW-",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75U_xZbRqOmn",
        "colab_type": "code",
        "outputId": "542f6cd4-1a6d-442d-9b2d-9bc83e224c50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Activation, Dense, Input\n",
        "from tensorflow.keras.layers import Conv2D, Flatten\n",
        "from tensorflow.keras.layers import Reshape, Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import concatenate\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "def build_generator(inputs, labels, image_size):\n",
        "    \n",
        "    image_resize = image_size // 4\n",
        "   \n",
        "    kernel_size = 5\n",
        "    layer_filters = [128, 64, 32, 1]\n",
        "\n",
        "    x = concatenate([inputs, labels], axis=1) # DCGAN과 달리 concatenate가 필요하다.\n",
        "    x = Dense(image_resize * image_resize * layer_filters[0])(x)\n",
        "    x = Reshape((image_resize, image_resize, layer_filters[0]))(x)\n",
        "\n",
        "    for filters in layer_filters:\n",
        "        \n",
        "        if filters > layer_filters[-2]:\n",
        "            strides = 2\n",
        "        else:\n",
        "            strides = 1\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2DTranspose(filters=filters,\n",
        "                            kernel_size=kernel_size,\n",
        "                            strides=strides,\n",
        "                            padding='same')(x)\n",
        "\n",
        "    x = Activation('sigmoid')(x)\n",
        "    generator = Model([inputs, labels], x, name='generator') # 입력은 y_labes에 의해 조건이 부여된다.\n",
        "    return generator\n",
        "\n",
        "def build_discriminator(inputs, labels, image_size):\n",
        "  \n",
        "    kernel_size = 5\n",
        "    layer_filters = [32, 64, 128, 256]\n",
        "\n",
        "    x = inputs\n",
        "\n",
        "    y = Dense(image_size * image_size)(labels)\n",
        "    y = Reshape((image_size, image_size, 1))(y)\n",
        "    x = concatenate([x, y])\n",
        "\n",
        "    for filters in layer_filters:\n",
        "        # first 3 convolution layers use strides = 2\n",
        "        # last one uses strides = 1\n",
        "        if filters == layer_filters[-1]:\n",
        "            strides = 1\n",
        "        else:\n",
        "            strides = 2\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        x = Conv2D(filters=filters,\n",
        "                   kernel_size=kernel_size,\n",
        "                   strides=strides,\n",
        "                   padding='same')(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(1)(x)\n",
        "    x = Activation('sigmoid')(x)\n",
        "    # input is conditioned by labels\n",
        "    discriminator = Model([inputs, labels], x, name='discriminator')\n",
        "    return discriminator\n",
        "\n",
        "def train(models, data, params):\n",
        "   \n",
        "    generator, discriminator, adversarial = models\n",
        "    x_train, y_train = data\n",
        "    batch_size, latent_size, train_steps, num_labels, model_name = params\n",
        "    save_interval = 500\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, latent_size])\n",
        "    noise_class = np.eye(num_labels)[np.arange(0, 16) % num_labels] \n",
        "    train_size = x_train.shape[0] \n",
        "\n",
        "    print(model_name,\n",
        "          \"Labels for generated images: \",\n",
        "          np.argmax(noise_class, axis=1))\n",
        "\n",
        "    for i in range(train_steps):\n",
        "       \n",
        "        rand_indexes = np.random.randint(0, train_size, size=batch_size)\n",
        "        real_images = x_train[rand_indexes]\n",
        "       \n",
        "        real_labels = y_train[rand_indexes]\n",
        "      \n",
        "        noise = np.random.uniform(-1.0,\n",
        "                                  1.0,\n",
        "                                  size=[batch_size, latent_size])\n",
        "       \n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n",
        "                                                          batch_size)]\n",
        "\n",
        "        fake_images = generator.predict([noise, fake_labels])\n",
        "        x = np.concatenate((real_images, fake_images))\n",
        "        labels = np.concatenate((real_labels, fake_labels))\n",
        "\n",
        "       \n",
        "        y[batch_size:, :] = 0.0\n",
        "        loss, acc = discriminator.train_on_batch([x, labels], y)\n",
        "        log = \"%d: [discriminator loss: %f, acc: %f]\" % (i, loss, acc)\n",
        "\n",
        "             \n",
        "        noise = np.random.uniform(-1.0,\n",
        "                                  1.0,\n",
        "                                  size=[batch_size, latent_size])\n",
        "        fake_labels = np.eye(num_labels)[np.random.choice(num_labels,\n",
        "                                                          batch_size)]\n",
        "        y = np.ones([batch_size, 1])\n",
        "        \n",
        "        loss, acc = adversarial.train_on_batch([noise, fake_labels], y)\n",
        "        log = \"%s [adversarial loss: %f, acc: %f]\" % (log, loss, acc)\n",
        "        print(log)\n",
        "        if (i + 1) % save_interval == 0:\n",
        "            plot_images(generator,\n",
        "                        noise_input=noise_input,\n",
        "                        noise_class=noise_class,\n",
        "                        show=False,\n",
        "                        step=(i + 1),\n",
        "                        model_name=model_name)\n",
        "    \n",
        "    generator.save(model_name + \".h5\")\n",
        "\n",
        "\n",
        "def plot_images(generator,\n",
        "                noise_input,\n",
        "                noise_class,\n",
        "                show=False,\n",
        "                step=0,\n",
        "                model_name=\"gan\"):\n",
        "    \"\"\"Generate fake images and plot them\n",
        "    For visualization purposes, generate fake images\n",
        "    then plot them in a square grid\n",
        "    Arguments:\n",
        "        generator (Model): The Generator Model for fake images generation\n",
        "        noise_input (ndarray): Array of z-vectors\n",
        "        show (bool): Whether to show plot or not\n",
        "        step (int): Appended to filename of the save images\n",
        "        model_name (string): Model name\n",
        "    \"\"\"\n",
        "    os.makedirs(model_name, exist_ok=True)\n",
        "    filename = os.path.join(model_name, \"%05d.png\" % step)\n",
        "    images = generator.predict([noise_input, noise_class])\n",
        "    print(model_name , \" labels for generated images: \", np.argmax(noise_class, axis=1))\n",
        "    plt.figure(figsize=(2.2, 2.2))\n",
        "    num_images = images.shape[0]\n",
        "    image_size = images.shape[1]\n",
        "    rows = int(math.sqrt(noise_input.shape[0]))\n",
        "    for i in range(num_images):\n",
        "        plt.subplot(rows, rows, i + 1)\n",
        "        image = np.reshape(images[i], [image_size, image_size])\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.savefig(filename)\n",
        "    if show:\n",
        "        plt.show()\n",
        "    else:\n",
        "        plt.close('all')\n",
        "\n",
        "\n",
        "def build_and_train_models():\n",
        "    # load MNIST dataset\n",
        "    (x_train, y_train), (_, _) = mnist.load_data()\n",
        "\n",
        "    # reshape data for CNN as (28, 28, 1) and normalize\n",
        "    image_size = x_train.shape[1]\n",
        "    x_train = np.reshape(x_train, [-1, image_size, image_size, 1])\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "\n",
        "    num_labels = np.amax(y_train) + 1\n",
        "    y_train = to_categorical(y_train)\n",
        "\n",
        "    model_name = \"cgan_mnist\"\n",
        "    # network parameters\n",
        "    # the latent or z vector is 100-dim\n",
        "    latent_size = 100\n",
        "    batch_size = 64\n",
        "    train_steps = 40000\n",
        "    lr = 2e-4\n",
        "    decay = 6e-8\n",
        "    input_shape = (image_size, image_size, 1)\n",
        "    label_shape = (num_labels, )\n",
        "\n",
        "    # build discriminator model\n",
        "    inputs = Input(shape=input_shape, name='discriminator_input')\n",
        "    labels = Input(shape=label_shape, name='class_labels')\n",
        "\n",
        "    discriminator = build_discriminator(inputs, labels, image_size)\n",
        "    # [1] or original paper uses Adam, \n",
        "    # but discriminator converges easily with RMSprop\n",
        "    optimizer = RMSprop(lr=lr, decay=decay)\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=optimizer,\n",
        "                          metrics=['accuracy'])\n",
        "    discriminator.summary()\n",
        "\n",
        "    # build generator model\n",
        "    input_shape = (latent_size, )\n",
        "    inputs = Input(shape=input_shape, name='z_input')\n",
        "    generator = build_generator(inputs, labels, image_size)\n",
        "    generator.summary()\n",
        "\n",
        "    # build adversarial model = generator + discriminator\n",
        "    optimizer = RMSprop(lr=lr*0.5, decay=decay*0.5)\n",
        "    # freeze the weights of discriminator during adversarial training\n",
        "    discriminator.trainable = False\n",
        "    outputs = discriminator([generator([inputs, labels]), labels])\n",
        "    adversarial = Model([inputs, labels],\n",
        "                        outputs,\n",
        "                        name=model_name)\n",
        "    adversarial.compile(loss='binary_crossentropy',\n",
        "                        optimizer=optimizer,\n",
        "                        metrics=['accuracy'])\n",
        "    adversarial.summary()\n",
        "\n",
        "    # train discriminator and adversarial networks\n",
        "    models = (generator, discriminator, adversarial)\n",
        "    data = (x_train, y_train)\n",
        "    params = (batch_size, latent_size, train_steps, num_labels, model_name)\n",
        "    train(models, data, params)\n",
        "\n",
        "\n",
        "def test_generator(generator, class_label=None):\n",
        "    noise_input = np.random.uniform(-1.0, 1.0, size=[16, 100])\n",
        "    step = 0\n",
        "    if class_label is None:\n",
        "        num_labels = 10\n",
        "        noise_class = np.eye(num_labels)[np.random.choice(num_labels, 16)]\n",
        "    else:\n",
        "        noise_class = np.zeros((16, 10))\n",
        "        noise_class[:,class_label] = 1\n",
        "        step = class_label\n",
        "\n",
        "    plot_images(generator,\n",
        "                noise_input=noise_input,\n",
        "                noise_class=noise_class,\n",
        "                show=True,\n",
        "                step=step,\n",
        "                model_name=\"test_outputs\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    help_ = \"Load generator h5 model with trained weights\"\n",
        "    parser.add_argument(\"-g\", \"--generator\", help=help_)\n",
        "    help_ = \"Specify a specific digit to generate\"\n",
        "    parser.add_argument(\"-d\", \"--digit\", type=int, help=help_)\n",
        "    args = parser.parse_args()\n",
        "    if args.generator:\n",
        "        generator = load_model(args.generator)\n",
        "        class_label = None\n",
        "        if args.digit is not None:\n",
        "            class_label = args.digit\n",
        "        test_generator(generator, class_label)\n",
        "    else:\n",
        "        build_and_train_models()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [-g GENERATOR] [-d DIGIT]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-a6c5beb1-e4e3-4cbf-be6b-8ea8dda381df.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pASlcZsQ8Gq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB75S2lUQ8LT",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXLe7NBNQ8QE",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCOE7q7oQ5gY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08APkKhFQvQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExfqPJZ5Q1Df",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}