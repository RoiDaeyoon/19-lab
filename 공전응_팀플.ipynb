{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "공전응 팀플",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91_%ED%8C%80%ED%94%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vqCxAiaNxlDd"
      },
      "source": [
        "영어와 어순이 다름\n",
        "난널 사랑해(O) 난 사랑해 널(X)\n",
        "S V O vs S O V\n",
        "\n",
        "3개의 단어 vs 2개의 단어\n",
        "\n",
        "I love you 가들어오고 이 벡터를 context vector로 번역이 되고 이를 번역이 시작하니깐 start 라는 인풋이 들어온다 \n",
        "\n",
        "Incoder Decoder Architecture 또는 Seq2Seq이라 한다. 인코더가 하는 역할은 단어를 순차적으로 입력함으로서 문맥벡터를 만드는 데에 있고 디코더의 역할은 문맥멕터로부터 정보를 받아 <start>로부터 <end>까지 기계번역을 시작한다.\n",
        "\n",
        "여기서 문제가 있다. 단어의 갯수가 적을때는 괜찮지만 단어의 갯수가 많아지면 문제가 생긴다. 왜냐하면 context vector는 하나의 고정된 사이즈의 벡터이기 때문에 context voctor가 작다면 모든 정보를 담지 못하게 된다. 충분한 정보가 없으므로 번역이 제대로 이루어지지 않게 된다.\n",
        "\n",
        "그래서 사용하는게 Attention vector를 자용한다.\n",
        "1. 고정된 사이즈의 문맥벡터가 아니다.\n",
        "2. 인코더의 모든 state 중에 집중해야 할 단어만 골라 따로 mechanism을 설계할 수 있다.\n",
        "\n",
        "인코더\n",
        "인코더 부분을 보면 전통적인 seq2seq에서와 같이 각각의 단어를 vector로 변환한다. 이 벡터들을 가지고 fully connected network층을 만든다. 그리고 h3를 한번더 넣어주는데 이는 현재로서는 디코더에서 나온 값이 하나도 없기 때문에 일단 기존의 스테이트를 한번더 넣어주는 것이다.\n",
        "\n",
        "이 FC layer를 통해 나온 값은 각각 score 1, 2, 3로 지정되며 이를 softmax 함수를 통해 확률값을 구한다. 이 값들은 attention weight라고 부르며 이 단어에 얼마나 focus를 할 것인지의 지표이다. 이 값들을 가지고 첫번째 contect vector를 만든다. 그리고 디코더 부분의 첫번째 cell에 넣어주게 되는데 여태까지 번역한게 없기 때문에 <start>라는 시그널을 넣어주게 된다. 그렇게되면 '난'이라는 아웃풋이 되고 이 cell에서 나온 state값이 이전에 구했던 FC layer에 다시 들어가게 된다. 중요한건 기존에 구했던 h1, h2, h3를 항상 쓰게 된다. 값을 넣어줌으로서 우리가 어떤 단어에 focus를 해야 할지 계산하여야 하기 때문이다. 이번에는 you가 0.9이므로 두번째 아웃풋으로 '널'이 된다. 한번더 하게 되면 '사랑해' 라는 값이 나오고 마지막으로 <end>라는 시그널이 나오게 된다.\n",
        "\n",
        "다음은 seq2seq with attention 모델과 기존 context vector의 결과를 비교한 그래프이다. 30, 50은 각각 maximum 30, 50개 단어를 통해서 학습을 한것이다. 결과는 보는거와 같이 attention method를 활용한 seq2seq 모델이 훨씬 좋은 결과를 보여주었다.\n",
        "\n",
        "Teacher Forcing\n",
        "만약에 predictio 값이 틀렸을 경우에 쓴다. 이 틀리값을 다시 집어넣게 되면 또 다시 틀린값이 나오게 되고 계속해서 오류가 커지게 된다. 이를 바로잡기 위해 prediction 값을 정답(난)을 넣어 줌으로서 학습이 좀더 빠르고 효율적이게 만들어준다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz7s57HqxTs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGLHrU-n9BIm",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/2.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vtxOREU9BFp",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/3.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71fZeVNC9BDL",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/4.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKBCdyQ29BBA",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/5.PNG?raw=true/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OI0Vzoc9A-m",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/6.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtLscpfr9A8V",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/7.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9Qfp1_A9AvD",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/8.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hjr2V4YA9mwR",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/9.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4cGUEZ_9qZt",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/10.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp_VVSNj9tqF",
        "colab_type": "text"
      },
      "source": [
        "![대체 텍스트](https://github.com/dockhs1313/19-lab/blob/master/%EA%B3%B5%EC%A0%84%EC%9D%91%20%EA%B8%B0%EB%A7%90%20%ED%8C%80%ED%94%8C/11.PNG?raw=true)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS1aJpTS9jnb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}