{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPq/BWXYaXAktW4p3CvQjOB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinhs0920/19-lab/blob/master/keras__mod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnrCCKpSQnbM",
        "colab_type": "text"
      },
      "source": [
        "# fashion_mnist : MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu-MPPRmCMgf",
        "colab_type": "code",
        "outputId": "b27de410-e510-489f-91e2-d764ff5ab63e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function \n",
        " \n",
        " \n",
        "# Keras 실행하기\n",
        "import keras  \n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Activation, Flatten \n",
        "from keras.datasets import fashion_mnist \n",
        " \n",
        " \n",
        "# 데이터 불러오기\n",
        "import numpy as np \n",
        "import os \n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.model_selection import train_test_split \n",
        " \n",
        " \n",
        "# 데이터를 훈련,평가 데이터로 나누기 / * 전처리를 데이터 불러오면서 동시에 할 수 없음\n",
        "x_train, y_train, x_valid, y_valid, x_test ,y_test = [], [], [], [], [], [] \n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data() \n",
        "x_train = x_train.reshape(60000,28,28) \n",
        "x_test = x_test.reshape(10000,28,28) \n",
        "\n",
        " \n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2) \n",
        " \n",
        "# 데이터 정규화 / * 정규화 방법 차이 설명 \n",
        "x_train = x_train.astype('float32') \n",
        "x_valid = x_valid.astype('float32') \n",
        "x_test = x_test.astype('float32') \n",
        "x_train /= 255 \n",
        "x_valid /= 255 \n",
        "x_test /= 255 \n",
        " \n",
        " \n",
        "x_train = x_train.reshape(len(x_train),28,28) \n",
        "x_test = x_test.reshape(10000,28,28) \n",
        "x_valid = x_valid.reshape(len(x_valid),28,28) \n",
        " \n",
        "# 원-핫 벡터로 변환 / * 케라스는 0과1 , 파이토치는 특정 값\n",
        "y_train = keras.utils.to_categorical(y_train, 10) \n",
        "y_valid = keras.utils.to_categorical(y_valid, 10) \n",
        "y_test = keras.utils.to_categorical(y_test, 10) \n",
        "\n",
        " \n",
        "# 모델 구축 : Flatten - Dense - Dropout - Softmax - SGD 최적화 / * 케라스 : 층을 각각 코드로 추가하여 모델을 구성해야함\n",
        "model = Sequential() \n",
        "model.add(Flatten(input_shape=(28,28))) \n",
        "model.add(Dense(256, activation='relu', kernel_initializer = 'he_normal' ,input_shape=(28*28,))) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(128, activation='relu',kernel_initializer = 'he_normal')) \n",
        "model.add(Dropout(0.2)) \n",
        "model.add(Dense(10, activation='softmax',kernel_initializer = 'he_normal')) \n",
        "optim = keras.optimizers.SGD(lr=0.01) \n",
        " \n",
        "# 최적화 방식 설명 \n",
        "model.compile(loss='categorical_crossentropy', \n",
        "\t\t\t  optimizer=optim, \n",
        " \t\t\t  metrics=['accuracy']) \n",
        " \n",
        "# 모델 훈련, 검증 \n",
        "history = model.fit(x_train, y_train,\n",
        " \t\t\t\t\t batch_size=64, \n",
        " \t\t\t\t\t epochs=50, \n",
        " \t\t\t\t\t verbose=2, \n",
        " \t\t\t\t\t validation_data=(x_valid, y_valid)) \n",
        " \n",
        " \n",
        "print(model.summary()) \n",
        "\n",
        "# 모델 평가  \t \n",
        "score = model.evaluate(x_test, y_test, verbose=0) \n",
        "print('Test loss:', score[0]) \n",
        "print('Test top 1 accuracy:', score[1]) \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            " - 3s - loss: 1.0052 - acc: 0.6594 - val_loss: 0.6206 - val_acc: 0.7989\n",
            "Epoch 2/50\n",
            " - 3s - loss: 0.6670 - acc: 0.7718 - val_loss: 0.5301 - val_acc: 0.8192\n",
            "Epoch 3/50\n",
            " - 3s - loss: 0.5874 - acc: 0.7988 - val_loss: 0.4846 - val_acc: 0.8342\n",
            "Epoch 4/50\n",
            " - 3s - loss: 0.5415 - acc: 0.8142 - val_loss: 0.4579 - val_acc: 0.8421\n",
            "Epoch 5/50\n",
            " - 3s - loss: 0.5116 - acc: 0.8210 - val_loss: 0.4407 - val_acc: 0.8446\n",
            "Epoch 6/50\n",
            " - 3s - loss: 0.4883 - acc: 0.8287 - val_loss: 0.4268 - val_acc: 0.8466\n",
            "Epoch 7/50\n",
            " - 3s - loss: 0.4731 - acc: 0.8341 - val_loss: 0.4150 - val_acc: 0.8522\n",
            "Epoch 8/50\n",
            " - 3s - loss: 0.4562 - acc: 0.8414 - val_loss: 0.4047 - val_acc: 0.8543\n",
            "Epoch 9/50\n",
            " - 3s - loss: 0.4446 - acc: 0.8447 - val_loss: 0.3950 - val_acc: 0.8572\n",
            "Epoch 10/50\n",
            " - 3s - loss: 0.4340 - acc: 0.8456 - val_loss: 0.3882 - val_acc: 0.8602\n",
            "Epoch 11/50\n",
            " - 3s - loss: 0.4231 - acc: 0.8505 - val_loss: 0.3806 - val_acc: 0.8627\n",
            "Epoch 12/50\n",
            " - 3s - loss: 0.4151 - acc: 0.8512 - val_loss: 0.3783 - val_acc: 0.8611\n",
            "Epoch 13/50\n",
            " - 3s - loss: 0.4100 - acc: 0.8558 - val_loss: 0.3708 - val_acc: 0.8662\n",
            "Epoch 14/50\n",
            " - 3s - loss: 0.3994 - acc: 0.8574 - val_loss: 0.3655 - val_acc: 0.8670\n",
            "Epoch 15/50\n",
            " - 3s - loss: 0.3966 - acc: 0.8581 - val_loss: 0.3641 - val_acc: 0.8682\n",
            "Epoch 16/50\n",
            " - 3s - loss: 0.3889 - acc: 0.8604 - val_loss: 0.3600 - val_acc: 0.8706\n",
            "Epoch 17/50\n",
            " - 3s - loss: 0.3822 - acc: 0.8630 - val_loss: 0.3573 - val_acc: 0.8718\n",
            "Epoch 18/50\n",
            " - 3s - loss: 0.3799 - acc: 0.8645 - val_loss: 0.3564 - val_acc: 0.8718\n",
            "Epoch 19/50\n",
            " - 3s - loss: 0.3741 - acc: 0.8676 - val_loss: 0.3501 - val_acc: 0.8751\n",
            "Epoch 20/50\n",
            " - 3s - loss: 0.3707 - acc: 0.8667 - val_loss: 0.3489 - val_acc: 0.8738\n",
            "Epoch 21/50\n",
            " - 3s - loss: 0.3655 - acc: 0.8689 - val_loss: 0.3439 - val_acc: 0.8743\n",
            "Epoch 22/50\n",
            " - 3s - loss: 0.3635 - acc: 0.8699 - val_loss: 0.3413 - val_acc: 0.8761\n",
            "Epoch 23/50\n",
            " - 3s - loss: 0.3584 - acc: 0.8713 - val_loss: 0.3409 - val_acc: 0.8765\n",
            "Epoch 24/50\n",
            " - 3s - loss: 0.3527 - acc: 0.8723 - val_loss: 0.3402 - val_acc: 0.8780\n",
            "Epoch 25/50\n",
            " - 3s - loss: 0.3521 - acc: 0.8751 - val_loss: 0.3367 - val_acc: 0.8789\n",
            "Epoch 26/50\n",
            " - 3s - loss: 0.3465 - acc: 0.8743 - val_loss: 0.3341 - val_acc: 0.8788\n",
            "Epoch 27/50\n",
            " - 3s - loss: 0.3436 - acc: 0.8756 - val_loss: 0.3326 - val_acc: 0.8777\n",
            "Epoch 28/50\n",
            " - 3s - loss: 0.3393 - acc: 0.8781 - val_loss: 0.3293 - val_acc: 0.8806\n",
            "Epoch 29/50\n",
            " - 3s - loss: 0.3376 - acc: 0.8799 - val_loss: 0.3290 - val_acc: 0.8828\n",
            "Epoch 30/50\n",
            " - 3s - loss: 0.3354 - acc: 0.8795 - val_loss: 0.3244 - val_acc: 0.8829\n",
            "Epoch 31/50\n",
            " - 3s - loss: 0.3304 - acc: 0.8813 - val_loss: 0.3237 - val_acc: 0.8838\n",
            "Epoch 32/50\n",
            " - 3s - loss: 0.3299 - acc: 0.8815 - val_loss: 0.3248 - val_acc: 0.8835\n",
            "Epoch 33/50\n",
            " - 3s - loss: 0.3253 - acc: 0.8823 - val_loss: 0.3217 - val_acc: 0.8850\n",
            "Epoch 34/50\n",
            " - 3s - loss: 0.3238 - acc: 0.8832 - val_loss: 0.3204 - val_acc: 0.8834\n",
            "Epoch 35/50\n",
            " - 3s - loss: 0.3220 - acc: 0.8853 - val_loss: 0.3197 - val_acc: 0.8853\n",
            "Epoch 36/50\n",
            " - 3s - loss: 0.3196 - acc: 0.8847 - val_loss: 0.3179 - val_acc: 0.8871\n",
            "Epoch 37/50\n",
            " - 3s - loss: 0.3159 - acc: 0.8869 - val_loss: 0.3261 - val_acc: 0.8820\n",
            "Epoch 38/50\n",
            " - 3s - loss: 0.3146 - acc: 0.8857 - val_loss: 0.3174 - val_acc: 0.8857\n",
            "Epoch 39/50\n",
            " - 3s - loss: 0.3111 - acc: 0.8891 - val_loss: 0.3160 - val_acc: 0.8858\n",
            "Epoch 40/50\n",
            " - 3s - loss: 0.3082 - acc: 0.8896 - val_loss: 0.3137 - val_acc: 0.8857\n",
            "Epoch 41/50\n",
            " - 3s - loss: 0.3076 - acc: 0.8892 - val_loss: 0.3197 - val_acc: 0.8859\n",
            "Epoch 42/50\n",
            " - 3s - loss: 0.3030 - acc: 0.8911 - val_loss: 0.3120 - val_acc: 0.8887\n",
            "Epoch 43/50\n",
            " - 3s - loss: 0.3034 - acc: 0.8905 - val_loss: 0.3095 - val_acc: 0.8867\n",
            "Epoch 44/50\n",
            " - 3s - loss: 0.3020 - acc: 0.8899 - val_loss: 0.3094 - val_acc: 0.8889\n",
            "Epoch 45/50\n",
            " - 3s - loss: 0.2995 - acc: 0.8924 - val_loss: 0.3121 - val_acc: 0.8885\n",
            "Epoch 46/50\n",
            " - 3s - loss: 0.2936 - acc: 0.8949 - val_loss: 0.3066 - val_acc: 0.8883\n",
            "Epoch 47/50\n",
            " - 3s - loss: 0.2942 - acc: 0.8934 - val_loss: 0.3068 - val_acc: 0.8876\n",
            "Epoch 48/50\n",
            " - 3s - loss: 0.2929 - acc: 0.8946 - val_loss: 0.3049 - val_acc: 0.8901\n",
            "Epoch 49/50\n",
            " - 3s - loss: 0.2905 - acc: 0.8946 - val_loss: 0.3050 - val_acc: 0.8908\n",
            "Epoch 50/50\n",
            " - 3s - loss: 0.2877 - acc: 0.8961 - val_loss: 0.3040 - val_acc: 0.8894\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_5 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 256)               200960    \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 235,146\n",
            "Trainable params: 235,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Test loss: 0.33367188571691514\n",
            "Test top 1 accuracy: 0.8803\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3KejN8Tnxyn",
        "colab_type": "text"
      },
      "source": [
        "# Fashion_Mnist : CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6p-ogQ1KD-_Y",
        "colab_type": "text"
      },
      "source": [
        "- CNN 모델<br>\n",
        "  MLP 모델과는 달리 MNIST 이미지에 대해 입력 벡터 배신 입력 텐서를 갖는다. 따라서 훈련/데이터 이미지 크기를 재조정해야한다.\n",
        "![대체 텍스트](https://github.com/syeong1218/keras-fig/blob/master/1.4.1.PNG?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iS9IxepE8pd",
        "colab_type": "text"
      },
      "source": [
        "### 1. Conv2D 계층을 사용한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLuJ_aa2EMpS",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- 커널<br> 전체 이미지를 움직이는 직사각형 패치\n",
        "![대체 텍스트](https://github.com/syeong1218/keras-fig/blob/master/1.4.2.PNG?raw=true)\n",
        "- 합성곱<br>  입력 이미지를 커널을 사용해 다른 행렬의 형태로 변형시키는 것. \n",
        "<br>이렇게 변형된 이미지를 특징 맵이라고 한다.\n",
        "![대체 텍스트](https://github.com/syeong1218/keras-fig/blob/master/1.4.3.PNG?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUrJixVeFD1T",
        "colab_type": "text"
      },
      "source": [
        "### 2. 폴링 연산"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uX_pGV8fFB6d",
        "colab_type": "text"
      },
      "source": [
        "MaxPooling2D 계층은 각 특징 맵을 압축한다. \n",
        "![대체 텍스트](https://github.com/syeong1218/keras-fig/blob/master/1.4.4.PNG?raw=true)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns_qZLfDFcr7",
        "colab_type": "text"
      },
      "source": [
        "### 3. Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7id2SDdaFBEO",
        "colab_type": "text"
      },
      "source": [
        "Conv2D 계층과 풀링 계층에서 나온 출력 값들을 텐서 형태에서 다시 행렬 형태로 바꾸어 준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13_xp4uWCQb5",
        "colab_type": "code",
        "outputId": "bb4fedb4-c5bb-487a-91af-56dba413fe0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# fashoin-mnist 데이터 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# 학습 셋 크기(shape) - 이미지 크기가 28x28 인 60,000 개의 학습 이미지 데이터, 60,000 개의 레이블\n",
        "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
        "\n",
        "# 이미지 값 정규화\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# 학습 데이터 셋을 학습 / 평가 셋으로 나눈다. (# 학습 셋: 55,000, 검증 셋: 5000)\n",
        "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
        "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
        "\n",
        "# 입력 이미지의 크기를 (28, 28) 에서 (28, 28, 1) 로 배열 차원을 변경(reshape)\n",
        "w, h = 28, 28\n",
        "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
        "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
        "\n",
        "# 레이블에 원-핫 인코딩 적용 \n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "# 모델 구현 / *간단 설명  - input_shape 형태 (텐서), 활성화함수 컨볼루션 매서드에서 직접 지정 \n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=10, ernel_size=5, padding='valid', activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(filters=20, kernel_size=5, padding='valid', activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 원-핫 벡터를 위한 손실 함수 / SGD 최적화 사용\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# 훈련 중간과 훈련 마지막에 체크포인트(checkpoint)를 자동으로 저장\n",
        "# 모델을 재사용하거나 훈련 과정이 중지된 경우 이어서 훈련을 진행.\n",
        "# Callbacks:  체크포인트 작업을 조정할 수 있도록 여러가지 매개변수를 제공\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
        "model.fit(x_train,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=40,\n",
        "         validation_data=(x_valid, y_valid),\n",
        "         callbacks=[checkpointer])\n",
        "\n",
        "# 가장 높은 검증 정확도의 가중치 불러오기\n",
        "model.load_weights('model.weights.best.hdf5')\n",
        "\n",
        "# 테스트 셋을 통해 모델 평가\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "# 테스트 정확도\n",
        "print('\\n', 'Test accuracy:', score[1])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
            "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_13 (Conv2D)           (None, 24, 24, 10)        260       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 12, 12, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 20)          5020      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 4, 4, 20)          0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 4, 4, 20)          0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 256)               82176     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 90,026\n",
            "Trainable params: 90,026\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/40\n",
            "54144/55000 [============================>.] - ETA: 0s - loss: 0.7355 - acc: 0.7280\n",
            "Epoch 00001: val_loss improved from inf to 0.43057, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 4s 70us/sample - loss: 0.7322 - acc: 0.7292 - val_loss: 0.4306 - val_acc: 0.8400\n",
            "Epoch 2/40\n",
            "54272/55000 [============================>.] - ETA: 0s - loss: 0.5081 - acc: 0.8130\n",
            "Epoch 00002: val_loss improved from 0.43057 to 0.36742, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.5076 - acc: 0.8133 - val_loss: 0.3674 - val_acc: 0.8670\n",
            "Epoch 3/40\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.4530 - acc: 0.8346\n",
            "Epoch 00003: val_loss improved from 0.36742 to 0.35202, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 59us/sample - loss: 0.4526 - acc: 0.8347 - val_loss: 0.3520 - val_acc: 0.8712\n",
            "Epoch 4/40\n",
            "54464/55000 [============================>.] - ETA: 0s - loss: 0.4190 - acc: 0.8458\n",
            "Epoch 00004: val_loss improved from 0.35202 to 0.31684, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 61us/sample - loss: 0.4191 - acc: 0.8457 - val_loss: 0.3168 - val_acc: 0.8836\n",
            "Epoch 5/40\n",
            "54592/55000 [============================>.] - ETA: 0s - loss: 0.3991 - acc: 0.8529\n",
            "Epoch 00005: val_loss improved from 0.31684 to 0.31252, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 61us/sample - loss: 0.3987 - acc: 0.8530 - val_loss: 0.3125 - val_acc: 0.8882\n",
            "Epoch 6/40\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.3872 - acc: 0.8591\n",
            "Epoch 00006: val_loss improved from 0.31252 to 0.29703, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 4s 64us/sample - loss: 0.3873 - acc: 0.8591 - val_loss: 0.2970 - val_acc: 0.8916\n",
            "Epoch 7/40\n",
            "54848/55000 [============================>.] - ETA: 0s - loss: 0.3764 - acc: 0.8607\n",
            "Epoch 00007: val_loss improved from 0.29703 to 0.28695, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 61us/sample - loss: 0.3764 - acc: 0.8607 - val_loss: 0.2869 - val_acc: 0.8914\n",
            "Epoch 8/40\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.3654 - acc: 0.8643\n",
            "Epoch 00008: val_loss did not improve from 0.28695\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3654 - acc: 0.8642 - val_loss: 0.2926 - val_acc: 0.8896\n",
            "Epoch 9/40\n",
            "54464/55000 [============================>.] - ETA: 0s - loss: 0.3598 - acc: 0.8668\n",
            "Epoch 00009: val_loss did not improve from 0.28695\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3601 - acc: 0.8666 - val_loss: 0.2874 - val_acc: 0.8978\n",
            "Epoch 10/40\n",
            "54272/55000 [============================>.] - ETA: 0s - loss: 0.3536 - acc: 0.8701\n",
            "Epoch 00010: val_loss improved from 0.28695 to 0.27215, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3531 - acc: 0.8704 - val_loss: 0.2722 - val_acc: 0.8982\n",
            "Epoch 11/40\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.3483 - acc: 0.8709\n",
            "Epoch 00011: val_loss did not improve from 0.27215\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3486 - acc: 0.8708 - val_loss: 0.2850 - val_acc: 0.8886\n",
            "Epoch 12/40\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.3480 - acc: 0.8713\n",
            "Epoch 00012: val_loss improved from 0.27215 to 0.26622, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3481 - acc: 0.8713 - val_loss: 0.2662 - val_acc: 0.8996\n",
            "Epoch 13/40\n",
            "54784/55000 [============================>.] - ETA: 0s - loss: 0.3432 - acc: 0.8738\n",
            "Epoch 00013: val_loss did not improve from 0.26622\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3429 - acc: 0.8738 - val_loss: 0.2676 - val_acc: 0.9030\n",
            "Epoch 14/40\n",
            "54592/55000 [============================>.] - ETA: 0s - loss: 0.3385 - acc: 0.8757\n",
            "Epoch 00014: val_loss did not improve from 0.26622\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3385 - acc: 0.8757 - val_loss: 0.2729 - val_acc: 0.8998\n",
            "Epoch 15/40\n",
            "54144/55000 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.8759\n",
            "Epoch 00015: val_loss improved from 0.26622 to 0.25823, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3373 - acc: 0.8760 - val_loss: 0.2582 - val_acc: 0.9032\n",
            "Epoch 16/40\n",
            "54720/55000 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.8767\n",
            "Epoch 00016: val_loss improved from 0.25823 to 0.25194, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3340 - acc: 0.8768 - val_loss: 0.2519 - val_acc: 0.9080\n",
            "Epoch 17/40\n",
            "54144/55000 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.8758\n",
            "Epoch 00017: val_loss did not improve from 0.25194\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3331 - acc: 0.8760 - val_loss: 0.2583 - val_acc: 0.9014\n",
            "Epoch 18/40\n",
            "54976/55000 [============================>.] - ETA: 0s - loss: 0.3296 - acc: 0.8785\n",
            "Epoch 00018: val_loss did not improve from 0.25194\n",
            "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3296 - acc: 0.8784 - val_loss: 0.2596 - val_acc: 0.9042\n",
            "Epoch 19/40\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.8783\n",
            "Epoch 00019: val_loss did not improve from 0.25194\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3284 - acc: 0.8784 - val_loss: 0.2556 - val_acc: 0.9058\n",
            "Epoch 20/40\n",
            "54016/55000 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.8799\n",
            "Epoch 00020: val_loss did not improve from 0.25194\n",
            "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3244 - acc: 0.8801 - val_loss: 0.2533 - val_acc: 0.9030\n",
            "Epoch 21/40\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.3276 - acc: 0.8782\n",
            "Epoch 00021: val_loss did not improve from 0.25194\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3273 - acc: 0.8783 - val_loss: 0.2549 - val_acc: 0.9050\n",
            "Epoch 22/40\n",
            "54400/55000 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.8796\n",
            "Epoch 00022: val_loss improved from 0.25194 to 0.25077, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3252 - acc: 0.8796 - val_loss: 0.2508 - val_acc: 0.9090\n",
            "Epoch 23/40\n",
            "54336/55000 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.8811\n",
            "Epoch 00023: val_loss did not improve from 0.25077\n",
            "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3221 - acc: 0.8809 - val_loss: 0.2595 - val_acc: 0.8990\n",
            "Epoch 24/40\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.8784\n",
            "Epoch 00024: val_loss improved from 0.25077 to 0.24595, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3238 - acc: 0.8785 - val_loss: 0.2459 - val_acc: 0.9076\n",
            "Epoch 25/40\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.3194 - acc: 0.8826\n",
            "Epoch 00025: val_loss did not improve from 0.24595\n",
            "55000/55000 [==============================] - 3s 58us/sample - loss: 0.3194 - acc: 0.8826 - val_loss: 0.2511 - val_acc: 0.9104\n",
            "Epoch 26/40\n",
            "54272/55000 [============================>.] - ETA: 0s - loss: 0.3175 - acc: 0.8832\n",
            "Epoch 00026: val_loss did not improve from 0.24595\n",
            "55000/55000 [==============================] - 3s 60us/sample - loss: 0.3174 - acc: 0.8833 - val_loss: 0.2486 - val_acc: 0.9058\n",
            "Epoch 27/40\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.3154 - acc: 0.8821\n",
            "Epoch 00027: val_loss did not improve from 0.24595\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3156 - acc: 0.8820 - val_loss: 0.2694 - val_acc: 0.9016\n",
            "Epoch 28/40\n",
            "54720/55000 [============================>.] - ETA: 0s - loss: 0.3167 - acc: 0.8822\n",
            "Epoch 00028: val_loss did not improve from 0.24595\n",
            "55000/55000 [==============================] - 3s 55us/sample - loss: 0.3168 - acc: 0.8822 - val_loss: 0.2585 - val_acc: 0.9026\n",
            "Epoch 29/40\n",
            "54528/55000 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.8822\n",
            "Epoch 00029: val_loss did not improve from 0.24595\n",
            "55000/55000 [==============================] - 3s 55us/sample - loss: 0.3175 - acc: 0.8822 - val_loss: 0.2528 - val_acc: 0.9104\n",
            "Epoch 30/40\n",
            "54720/55000 [============================>.] - ETA: 0s - loss: 0.3121 - acc: 0.8836\n",
            "Epoch 00030: val_loss did not improve from 0.24595\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3117 - acc: 0.8837 - val_loss: 0.2479 - val_acc: 0.9070\n",
            "Epoch 31/40\n",
            "54464/55000 [============================>.] - ETA: 0s - loss: 0.3160 - acc: 0.8824\n",
            "Epoch 00031: val_loss did not improve from 0.24595\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3160 - acc: 0.8823 - val_loss: 0.2492 - val_acc: 0.9114\n",
            "Epoch 32/40\n",
            "54464/55000 [============================>.] - ETA: 0s - loss: 0.3133 - acc: 0.8834\n",
            "Epoch 00032: val_loss did not improve from 0.24595\n",
            "55000/55000 [==============================] - 3s 55us/sample - loss: 0.3131 - acc: 0.8834 - val_loss: 0.2619 - val_acc: 0.9032\n",
            "Epoch 33/40\n",
            "54592/55000 [============================>.] - ETA: 0s - loss: 0.3106 - acc: 0.8849\n",
            "Epoch 00033: val_loss improved from 0.24595 to 0.24496, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 57us/sample - loss: 0.3110 - acc: 0.8848 - val_loss: 0.2450 - val_acc: 0.9100\n",
            "Epoch 34/40\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.3090 - acc: 0.8848\n",
            "Epoch 00034: val_loss did not improve from 0.24496\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3095 - acc: 0.8847 - val_loss: 0.2670 - val_acc: 0.9026\n",
            "Epoch 35/40\n",
            "54976/55000 [============================>.] - ETA: 0s - loss: 0.3086 - acc: 0.8855\n",
            "Epoch 00035: val_loss did not improve from 0.24496\n",
            "55000/55000 [==============================] - 3s 55us/sample - loss: 0.3086 - acc: 0.8855 - val_loss: 0.2609 - val_acc: 0.9024\n",
            "Epoch 36/40\n",
            "54912/55000 [============================>.] - ETA: 0s - loss: 0.3093 - acc: 0.8860\n",
            "Epoch 00036: val_loss improved from 0.24496 to 0.24458, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3094 - acc: 0.8859 - val_loss: 0.2446 - val_acc: 0.9122\n",
            "Epoch 37/40\n",
            "54656/55000 [============================>.] - ETA: 0s - loss: 0.3081 - acc: 0.8861\n",
            "Epoch 00037: val_loss improved from 0.24458 to 0.23899, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 59us/sample - loss: 0.3079 - acc: 0.8862 - val_loss: 0.2390 - val_acc: 0.9100\n",
            "Epoch 38/40\n",
            "54208/55000 [============================>.] - ETA: 0s - loss: 0.3103 - acc: 0.8841\n",
            "Epoch 00038: val_loss improved from 0.23899 to 0.23864, saving model to model.weights.best.hdf5\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3100 - acc: 0.8842 - val_loss: 0.2386 - val_acc: 0.9130\n",
            "Epoch 39/40\n",
            "54464/55000 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.8870\n",
            "Epoch 00039: val_loss did not improve from 0.23864\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3078 - acc: 0.8869 - val_loss: 0.2417 - val_acc: 0.9148\n",
            "Epoch 40/40\n",
            "54848/55000 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.8870\n",
            "Epoch 00040: val_loss did not improve from 0.23864\n",
            "55000/55000 [==============================] - 3s 56us/sample - loss: 0.3043 - acc: 0.8870 - val_loss: 0.2659 - val_acc: 0.9010\n",
            "\n",
            " Test accuracy: 0.9003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nm9QSbSpiy9",
        "colab_type": "text"
      },
      "source": [
        "# Fashion_Mnist : ResNet(VER.1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss-s-Tk-_XJt",
        "colab_type": "code",
        "outputId": "a59abdc0-9b0a-4ae4-89bd-f4952b118ed8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation\n",
        "from tensorflow.keras.layers import AveragePooling2D, Input\n",
        "from tensorflow.keras.layers import Flatten, add\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 훈련 매개변수\n",
        "batch_size = 32\n",
        "epochs = 200\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# 모델 파라미터 - 모델 선정 방식\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 3\n",
        "\n",
        "# 모델 버전\n",
        "# 최초 논문: version = 1 (ResNet v1), \n",
        "version = 1\n",
        "\n",
        "# 제공된 모델 매개변수 n으로부터 계산된 네트워크 깊이\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# CIFAR10 데이터 불러오기\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# 정규화\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# if subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\" 학습률은 lr_schedule()을 통해 80, 120, 160, 180 epochs 에서 시작하여 점차 감소시킨다.\n",
        "    기본값은 1e-3 이다. lr_schedule()함수는 모델 훈련동안 한 epoch 당 callbacks 변수로 호출된다.\n",
        "\n",
        "    # Arguments\n",
        "        에폭의 수 :-> epoch (int)\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "    Arguments:\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "    Returns:\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal', # 역전파 시 수렴될 수 있게 해주는 것\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, in [a])')\n",
        "    \n",
        "    # 모델 정의 시작\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    \n",
        "    # 잔차 유닛 인스턴스화\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "           \n",
        "            if stack > 0 and res_block == 0:  \n",
        "                strides = 2  \n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            \n",
        "            if stack > 0 and res_block == 0:\n",
        "               \n",
        "               # 변경된 차원을 맞추기 위해 잔차 숏컷 연결을 선형으로 사영 \n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # 분류기 추가\n",
        "    # v1은 마지막 숏컷 연결-ReLU 후에는 BN을 사용하지 않는다.\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # 모델 인스턴스화\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "#ResNet v2 구현\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "   \n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
        "   \n",
        "   # 모델 정의\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "   # v2에서는 2 경로로 나뉘기 전에 입력에 BN-ReLU와 함께 Conv2D를 수행 \n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    \n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                # first layer and first stage\n",
        "                if res_block == 0:  \n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "               \n",
        "                if res_block == 0:\n",
        "                   \n",
        "                    strides = 2 \n",
        "\n",
        "           \n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "              \n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
        "print(model_type)\n",
        "\n",
        "# prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_accuracy',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # this will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False)\n",
        "\n",
        "    # compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, \n",
        "                        steps_per_epoch=len(x_train)//batch_size,\n",
        "                        callbacks=callbacks)\n",
        "\n",
        "# score trained model\n",
        "scores = model.evaluate(x_test,\n",
        "                        y_test,\n",
        "                        batch_size=batch_size,\n",
        "                        verbose=0)\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 32, 32, 16)   448         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 32, 32, 16)   64          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 32, 32, 16)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 32, 32, 16)   2320        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32, 32, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 32, 32, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 32, 32, 16)   2320        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 32, 32, 16)   64          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 32, 32, 16)   0           activation[0][0]                 \n",
            "                                                                 batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 32, 32, 16)   0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 32, 32, 16)   2320        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 32, 32, 16)   64          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 32, 32, 16)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 32, 32, 16)   2320        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 32, 32, 16)   64          conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 32, 32, 16)   0           activation_2[0][0]               \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 32, 32, 16)   0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 32, 32, 16)   2320        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 32, 32, 16)   64          conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 32, 32, 16)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 32, 32, 16)   2320        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 16)   64          conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 32, 32, 16)   0           activation_4[0][0]               \n",
            "                                                                 batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 16)   0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 32)   4640        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 32)   128         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 32)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 32)   9248        activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 32)   544         activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 32)   128         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 32)   0           conv2d_9[0][0]                   \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 32)   0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 32)   9248        activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 32)   128         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   9248        activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 32)   128         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 32)   0           activation_8[0][0]               \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 32)   0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 32)   9248        activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   128         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 32)   9248        activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 32)   128         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 32)   0           activation_10[0][0]              \n",
            "                                                                 batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 32)   0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 8, 8, 64)     18496       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 8, 8, 64)     256         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 8, 8, 64)     0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 8, 8, 64)     36928       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 8, 8, 64)     2112        activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 8, 8, 64)     256         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 8, 8, 64)     0           conv2d_16[0][0]                  \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 8, 8, 64)     0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 8, 8, 64)     36928       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 8, 8, 64)     256         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 8, 8, 64)     0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 8, 8, 64)     36928       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 8, 8, 64)     256         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 64)     0           activation_14[0][0]              \n",
            "                                                                 batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 8, 8, 64)     0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 8, 8, 64)     36928       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 8, 8, 64)     256         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 8, 8, 64)     0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 8, 8, 64)     36928       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 8, 8, 64)     256         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 64)     0           activation_16[0][0]              \n",
            "                                                                 batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 8, 8, 64)     0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 1, 1, 64)     0           activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 64)           0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 10)           650         flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 274,442\n",
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n",
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 1.5537 - acc: 0.4945Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 229us/sample - loss: 1.3871 - acc: 0.5530\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 49s 31ms/step - loss: 1.5530 - acc: 0.4947 - val_loss: 1.3967 - val_acc: 0.5530\n",
            "Learning rate:  0.001\n",
            "Epoch 2/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 1.1744 - acc: 0.6394Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 1.1545 - acc: 0.6198\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 1.1745 - acc: 0.6394 - val_loss: 1.2637 - val_acc: 0.6198\n",
            "Learning rate:  0.001\n",
            "Epoch 3/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 1.0148 - acc: 0.6998Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 188us/sample - loss: 0.9808 - acc: 0.6762\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 1.0149 - acc: 0.6998 - val_loss: 1.1252 - val_acc: 0.6762\n",
            "Learning rate:  0.001\n",
            "Epoch 4/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.9151 - acc: 0.7382Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 1.1401 - acc: 0.7126\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.9151 - acc: 0.7382 - val_loss: 1.0471 - val_acc: 0.7126\n",
            "Learning rate:  0.001\n",
            "Epoch 5/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.8526 - acc: 0.7630Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 1.0616 - acc: 0.7047\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.8524 - acc: 0.7631 - val_loss: 1.0688 - val_acc: 0.7047\n",
            "Learning rate:  0.001\n",
            "Epoch 6/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.8061 - acc: 0.7802Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.8720 - acc: 0.7511\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.8060 - acc: 0.7802 - val_loss: 0.9124 - val_acc: 0.7511\n",
            "Learning rate:  0.001\n",
            "Epoch 7/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.7732 - acc: 0.7936Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 203us/sample - loss: 0.7540 - acc: 0.7866\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.7732 - acc: 0.7936 - val_loss: 0.8110 - val_acc: 0.7866\n",
            "Learning rate:  0.001\n",
            "Epoch 8/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.7463 - acc: 0.8035Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 202us/sample - loss: 1.0527 - acc: 0.7307\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.7463 - acc: 0.8035 - val_loss: 0.9805 - val_acc: 0.7307\n",
            "Learning rate:  0.001\n",
            "Epoch 9/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.7215 - acc: 0.8127Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.8863 - acc: 0.7797\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.7216 - acc: 0.8126 - val_loss: 0.8447 - val_acc: 0.7797\n",
            "Learning rate:  0.001\n",
            "Epoch 10/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.7010 - acc: 0.8234Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 1.0639 - acc: 0.7116\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.7010 - acc: 0.8234 - val_loss: 1.1382 - val_acc: 0.7116\n",
            "Learning rate:  0.001\n",
            "Epoch 11/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.6902 - acc: 0.8246Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.6582 - acc: 0.8013\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.6902 - acc: 0.8246 - val_loss: 0.7801 - val_acc: 0.8013\n",
            "Learning rate:  0.001\n",
            "Epoch 12/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.6709 - acc: 0.8327Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.9385 - acc: 0.7125\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.6709 - acc: 0.8327 - val_loss: 1.1510 - val_acc: 0.7125\n",
            "Learning rate:  0.001\n",
            "Epoch 13/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.6601 - acc: 0.8363Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 203us/sample - loss: 0.8538 - acc: 0.7880\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.6602 - acc: 0.8363 - val_loss: 0.8154 - val_acc: 0.7880\n",
            "Learning rate:  0.001\n",
            "Epoch 14/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.6512 - acc: 0.8401Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.7166 - acc: 0.7839\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.6513 - acc: 0.8400 - val_loss: 0.8271 - val_acc: 0.7839\n",
            "Learning rate:  0.001\n",
            "Epoch 15/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.6389 - acc: 0.8463Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 200us/sample - loss: 0.7016 - acc: 0.8147\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.6389 - acc: 0.8464 - val_loss: 0.7382 - val_acc: 0.8147\n",
            "Learning rate:  0.001\n",
            "Epoch 16/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.6281 - acc: 0.8518Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.9285 - acc: 0.7776\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.6282 - acc: 0.8518 - val_loss: 0.8711 - val_acc: 0.7776\n",
            "Learning rate:  0.001\n",
            "Epoch 17/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.6246 - acc: 0.8517Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.9511 - acc: 0.8121\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.6246 - acc: 0.8517 - val_loss: 0.7672 - val_acc: 0.8121\n",
            "Learning rate:  0.001\n",
            "Epoch 18/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.6116 - acc: 0.8553Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 198us/sample - loss: 0.9428 - acc: 0.8005\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.6116 - acc: 0.8553 - val_loss: 0.8414 - val_acc: 0.8005\n",
            "Learning rate:  0.001\n",
            "Epoch 19/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.6107 - acc: 0.8594Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.7293 - acc: 0.8337\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.6107 - acc: 0.8593 - val_loss: 0.7118 - val_acc: 0.8337\n",
            "Learning rate:  0.001\n",
            "Epoch 20/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.6001 - acc: 0.8625Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.7857 - acc: 0.7802\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5999 - acc: 0.8625 - val_loss: 0.8940 - val_acc: 0.7802\n",
            "Learning rate:  0.001\n",
            "Epoch 21/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5931 - acc: 0.8643Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 1.1059 - acc: 0.7720\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5931 - acc: 0.8643 - val_loss: 0.9094 - val_acc: 0.7720\n",
            "Learning rate:  0.001\n",
            "Epoch 22/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5923 - acc: 0.8645Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 196us/sample - loss: 0.7809 - acc: 0.8119\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5922 - acc: 0.8645 - val_loss: 0.7691 - val_acc: 0.8119\n",
            "Learning rate:  0.001\n",
            "Epoch 23/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5883 - acc: 0.8657Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 1.0291 - acc: 0.8120\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5884 - acc: 0.8657 - val_loss: 0.7634 - val_acc: 0.8120\n",
            "Learning rate:  0.001\n",
            "Epoch 24/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5810 - acc: 0.8680Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 200us/sample - loss: 0.5899 - acc: 0.8274\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.5809 - acc: 0.8681 - val_loss: 0.7370 - val_acc: 0.8274\n",
            "Learning rate:  0.001\n",
            "Epoch 25/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5794 - acc: 0.8702Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.6941 - acc: 0.8472\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5794 - acc: 0.8702 - val_loss: 0.6611 - val_acc: 0.8472\n",
            "Learning rate:  0.001\n",
            "Epoch 26/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5773 - acc: 0.8701Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 197us/sample - loss: 0.6945 - acc: 0.8536\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5773 - acc: 0.8701 - val_loss: 0.6625 - val_acc: 0.8536\n",
            "Learning rate:  0.001\n",
            "Epoch 27/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5722 - acc: 0.8732Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.9837 - acc: 0.8135\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5724 - acc: 0.8732 - val_loss: 0.7879 - val_acc: 0.8135\n",
            "Learning rate:  0.001\n",
            "Epoch 28/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5668 - acc: 0.8718Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.7239 - acc: 0.8386\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5669 - acc: 0.8718 - val_loss: 0.7007 - val_acc: 0.8386\n",
            "Learning rate:  0.001\n",
            "Epoch 29/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5604 - acc: 0.8753Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.7183 - acc: 0.8247\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5603 - acc: 0.8753 - val_loss: 0.7291 - val_acc: 0.8247\n",
            "Learning rate:  0.001\n",
            "Epoch 30/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5602 - acc: 0.8765Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.6117 - acc: 0.8455\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5601 - acc: 0.8765 - val_loss: 0.6766 - val_acc: 0.8455\n",
            "Learning rate:  0.001\n",
            "Epoch 31/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5572 - acc: 0.8782Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.6673 - acc: 0.8253\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5571 - acc: 0.8783 - val_loss: 0.7319 - val_acc: 0.8253\n",
            "Learning rate:  0.001\n",
            "Epoch 32/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5578 - acc: 0.8785Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.5881 - acc: 0.8380\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.5577 - acc: 0.8785 - val_loss: 0.6855 - val_acc: 0.8380\n",
            "Learning rate:  0.001\n",
            "Epoch 33/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5535 - acc: 0.8806Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.6572 - acc: 0.8178\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5536 - acc: 0.8805 - val_loss: 0.7646 - val_acc: 0.8178\n",
            "Learning rate:  0.001\n",
            "Epoch 34/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5451 - acc: 0.8841Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.5582 - acc: 0.8591\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5452 - acc: 0.8840 - val_loss: 0.6227 - val_acc: 0.8591\n",
            "Learning rate:  0.001\n",
            "Epoch 35/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5464 - acc: 0.8843Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 199us/sample - loss: 0.6090 - acc: 0.8505\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5464 - acc: 0.8843 - val_loss: 0.6577 - val_acc: 0.8505\n",
            "Learning rate:  0.001\n",
            "Epoch 36/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5420 - acc: 0.8838Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.9802 - acc: 0.7842\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5420 - acc: 0.8839 - val_loss: 0.9224 - val_acc: 0.7842\n",
            "Learning rate:  0.001\n",
            "Epoch 37/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5476 - acc: 0.8805Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.7806 - acc: 0.8189\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5476 - acc: 0.8804 - val_loss: 0.7517 - val_acc: 0.8189\n",
            "Learning rate:  0.001\n",
            "Epoch 38/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5378 - acc: 0.8844Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.7213 - acc: 0.8378\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5385 - acc: 0.8843 - val_loss: 0.7062 - val_acc: 0.8378\n",
            "Learning rate:  0.001\n",
            "Epoch 39/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5394 - acc: 0.8840Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.6773 - acc: 0.8207\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5395 - acc: 0.8840 - val_loss: 0.7424 - val_acc: 0.8207\n",
            "Learning rate:  0.001\n",
            "Epoch 40/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5360 - acc: 0.8868Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.7300 - acc: 0.8315\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.5359 - acc: 0.8868 - val_loss: 0.7355 - val_acc: 0.8315\n",
            "Learning rate:  0.001\n",
            "Epoch 41/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5326 - acc: 0.8884Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 199us/sample - loss: 0.7751 - acc: 0.8353\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5326 - acc: 0.8884 - val_loss: 0.7088 - val_acc: 0.8353\n",
            "Learning rate:  0.001\n",
            "Epoch 42/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5342 - acc: 0.8886Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.7632 - acc: 0.8469\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5341 - acc: 0.8886 - val_loss: 0.6936 - val_acc: 0.8469\n",
            "Learning rate:  0.001\n",
            "Epoch 43/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5311 - acc: 0.8897Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.6551 - acc: 0.8667\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5311 - acc: 0.8897 - val_loss: 0.6129 - val_acc: 0.8667\n",
            "Learning rate:  0.001\n",
            "Epoch 44/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5315 - acc: 0.8886Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.8423 - acc: 0.8087\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5316 - acc: 0.8885 - val_loss: 0.8224 - val_acc: 0.8087\n",
            "Learning rate:  0.001\n",
            "Epoch 45/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5270 - acc: 0.8897Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 200us/sample - loss: 0.7667 - acc: 0.8488\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5270 - acc: 0.8897 - val_loss: 0.6772 - val_acc: 0.8488\n",
            "Learning rate:  0.001\n",
            "Epoch 46/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5281 - acc: 0.8913Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 203us/sample - loss: 0.7185 - acc: 0.8442\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.5285 - acc: 0.8912 - val_loss: 0.6761 - val_acc: 0.8442\n",
            "Learning rate:  0.001\n",
            "Epoch 47/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5270 - acc: 0.8899Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.6732 - acc: 0.8534\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.5270 - acc: 0.8899 - val_loss: 0.6690 - val_acc: 0.8534\n",
            "Learning rate:  0.001\n",
            "Epoch 48/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5253 - acc: 0.8910Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.5731 - acc: 0.8513\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.5253 - acc: 0.8910 - val_loss: 0.6528 - val_acc: 0.8513\n",
            "Learning rate:  0.001\n",
            "Epoch 49/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5236 - acc: 0.8911Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.6277 - acc: 0.8520\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5235 - acc: 0.8912 - val_loss: 0.6558 - val_acc: 0.8520\n",
            "Learning rate:  0.001\n",
            "Epoch 50/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5224 - acc: 0.8912Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 196us/sample - loss: 0.7947 - acc: 0.8311\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5227 - acc: 0.8912 - val_loss: 0.7222 - val_acc: 0.8311\n",
            "Learning rate:  0.001\n",
            "Epoch 51/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.8922Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 196us/sample - loss: 0.5819 - acc: 0.8530\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5199 - acc: 0.8920 - val_loss: 0.6644 - val_acc: 0.8530\n",
            "Learning rate:  0.001\n",
            "Epoch 52/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.8924Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.5999 - acc: 0.8440\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5228 - acc: 0.8925 - val_loss: 0.6551 - val_acc: 0.8440\n",
            "Learning rate:  0.001\n",
            "Epoch 53/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5159 - acc: 0.8938Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.6702 - acc: 0.8384\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5158 - acc: 0.8939 - val_loss: 0.7125 - val_acc: 0.8384\n",
            "Learning rate:  0.001\n",
            "Epoch 54/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5199 - acc: 0.8924Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.5154 - acc: 0.8571\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5197 - acc: 0.8924 - val_loss: 0.6397 - val_acc: 0.8571\n",
            "Learning rate:  0.001\n",
            "Epoch 55/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5152 - acc: 0.8943Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.6026 - acc: 0.8506\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5151 - acc: 0.8944 - val_loss: 0.6752 - val_acc: 0.8506\n",
            "Learning rate:  0.001\n",
            "Epoch 56/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.8951Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.8718 - acc: 0.8325\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.5152 - acc: 0.8950 - val_loss: 0.7584 - val_acc: 0.8325\n",
            "Learning rate:  0.001\n",
            "Epoch 57/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5115 - acc: 0.8957Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.7039 - acc: 0.8627\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5113 - acc: 0.8958 - val_loss: 0.6441 - val_acc: 0.8627\n",
            "Learning rate:  0.001\n",
            "Epoch 58/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.8965Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.7022 - acc: 0.8508\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5100 - acc: 0.8965 - val_loss: 0.6763 - val_acc: 0.8508\n",
            "Learning rate:  0.001\n",
            "Epoch 59/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5116 - acc: 0.8957Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.5679 - acc: 0.8598\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5115 - acc: 0.8957 - val_loss: 0.6276 - val_acc: 0.8598\n",
            "Learning rate:  0.001\n",
            "Epoch 60/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5110 - acc: 0.8955Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.7084 - acc: 0.8411\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5110 - acc: 0.8955 - val_loss: 0.7159 - val_acc: 0.8411\n",
            "Learning rate:  0.001\n",
            "Epoch 61/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5078 - acc: 0.8956Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.5235 - acc: 0.8464\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5076 - acc: 0.8956 - val_loss: 0.6867 - val_acc: 0.8464\n",
            "Learning rate:  0.001\n",
            "Epoch 62/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5085 - acc: 0.8965Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 196us/sample - loss: 0.5815 - acc: 0.8427\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5085 - acc: 0.8965 - val_loss: 0.7149 - val_acc: 0.8427\n",
            "Learning rate:  0.001\n",
            "Epoch 63/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5029 - acc: 0.8981Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.6123 - acc: 0.8673\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5030 - acc: 0.8981 - val_loss: 0.6116 - val_acc: 0.8673\n",
            "Learning rate:  0.001\n",
            "Epoch 64/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.8974Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 196us/sample - loss: 0.6697 - acc: 0.8534\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.5070 - acc: 0.8973 - val_loss: 0.6421 - val_acc: 0.8534\n",
            "Learning rate:  0.001\n",
            "Epoch 65/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5042 - acc: 0.8977Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.5862 - acc: 0.8570\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5041 - acc: 0.8977 - val_loss: 0.6353 - val_acc: 0.8570\n",
            "Learning rate:  0.001\n",
            "Epoch 66/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5010 - acc: 0.8994Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 197us/sample - loss: 0.9545 - acc: 0.8494\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.5010 - acc: 0.8994 - val_loss: 0.6981 - val_acc: 0.8494\n",
            "Learning rate:  0.001\n",
            "Epoch 67/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.5018 - acc: 0.9002Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.6055 - acc: 0.8605\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5018 - acc: 0.9003 - val_loss: 0.6356 - val_acc: 0.8605\n",
            "Learning rate:  0.001\n",
            "Epoch 68/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5000 - acc: 0.9007Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.6629 - acc: 0.8560\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5000 - acc: 0.9007 - val_loss: 0.6746 - val_acc: 0.8560\n",
            "Learning rate:  0.001\n",
            "Epoch 69/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.4989 - acc: 0.8992Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.6506 - acc: 0.8450\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4989 - acc: 0.8992 - val_loss: 0.6938 - val_acc: 0.8450\n",
            "Learning rate:  0.001\n",
            "Epoch 70/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.8996Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.6012 - acc: 0.8590\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5024 - acc: 0.8996 - val_loss: 0.6464 - val_acc: 0.8590\n",
            "Learning rate:  0.001\n",
            "Epoch 71/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.4979 - acc: 0.9013Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.8015 - acc: 0.8146\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4980 - acc: 0.9013 - val_loss: 0.8052 - val_acc: 0.8146\n",
            "Learning rate:  0.001\n",
            "Epoch 72/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.4955 - acc: 0.9026Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 203us/sample - loss: 0.9669 - acc: 0.8160\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4955 - acc: 0.9026 - val_loss: 0.7656 - val_acc: 0.8160\n",
            "Learning rate:  0.001\n",
            "Epoch 73/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.5013 - acc: 0.9008Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.9394 - acc: 0.8543\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.5014 - acc: 0.9008 - val_loss: 0.6534 - val_acc: 0.8543\n",
            "Learning rate:  0.001\n",
            "Epoch 74/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.8995Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.8510 - acc: 0.8442\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4988 - acc: 0.8995 - val_loss: 0.6879 - val_acc: 0.8442\n",
            "Learning rate:  0.001\n",
            "Epoch 75/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.9021Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.6455 - acc: 0.8764\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.4938 - acc: 0.9022 - val_loss: 0.6001 - val_acc: 0.8764\n",
            "Learning rate:  0.001\n",
            "Epoch 76/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.4924 - acc: 0.9022Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 1.0737 - acc: 0.8280\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4924 - acc: 0.9022 - val_loss: 0.7942 - val_acc: 0.8280\n",
            "Learning rate:  0.001\n",
            "Epoch 77/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.5001 - acc: 0.9008Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.5436 - acc: 0.8485\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4999 - acc: 0.9009 - val_loss: 0.6742 - val_acc: 0.8485\n",
            "Learning rate:  0.001\n",
            "Epoch 78/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.9009Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.7349 - acc: 0.8212\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4965 - acc: 0.9009 - val_loss: 0.7955 - val_acc: 0.8212\n",
            "Learning rate:  0.001\n",
            "Epoch 79/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.4900 - acc: 0.9044Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.7316 - acc: 0.8107\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4902 - acc: 0.9043 - val_loss: 0.8361 - val_acc: 0.8107\n",
            "Learning rate:  0.001\n",
            "Epoch 80/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.4911 - acc: 0.9035Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.5810 - acc: 0.8573\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4911 - acc: 0.9035 - val_loss: 0.6263 - val_acc: 0.8573\n",
            "Learning rate:  0.001\n",
            "Epoch 81/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.4914 - acc: 0.9027Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.5786 - acc: 0.8662\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.4914 - acc: 0.9027 - val_loss: 0.6264 - val_acc: 0.8662\n",
            "Learning rate:  0.0001\n",
            "Epoch 82/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.4106 - acc: 0.9312Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4921 - acc: 0.9043\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.4105 - acc: 0.9312 - val_loss: 0.5003 - val_acc: 0.9043\n",
            "Learning rate:  0.0001\n",
            "Epoch 83/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.3757 - acc: 0.9411Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 197us/sample - loss: 0.4631 - acc: 0.9080\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.3756 - acc: 0.9411 - val_loss: 0.4889 - val_acc: 0.9080\n",
            "Learning rate:  0.0001\n",
            "Epoch 84/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.3623 - acc: 0.9439Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.4483 - acc: 0.9093\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.3623 - acc: 0.9439 - val_loss: 0.4796 - val_acc: 0.9093\n",
            "Learning rate:  0.0001\n",
            "Epoch 85/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.3467 - acc: 0.9480Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4505 - acc: 0.9098\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.3467 - acc: 0.9480 - val_loss: 0.4738 - val_acc: 0.9098\n",
            "Learning rate:  0.0001\n",
            "Epoch 86/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.9520Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4534 - acc: 0.9118\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.3364 - acc: 0.9519 - val_loss: 0.4677 - val_acc: 0.9118\n",
            "Learning rate:  0.0001\n",
            "Epoch 87/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.3238 - acc: 0.9542Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4256 - acc: 0.9090\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.3238 - acc: 0.9542 - val_loss: 0.4684 - val_acc: 0.9090\n",
            "Learning rate:  0.0001\n",
            "Epoch 88/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.3184 - acc: 0.9545Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.4224 - acc: 0.9117\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.3185 - acc: 0.9545 - val_loss: 0.4677 - val_acc: 0.9117\n",
            "Learning rate:  0.0001\n",
            "Epoch 89/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.3107 - acc: 0.9569Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4076 - acc: 0.9120\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.3107 - acc: 0.9569 - val_loss: 0.4593 - val_acc: 0.9120\n",
            "Learning rate:  0.0001\n",
            "Epoch 90/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.3101 - acc: 0.9545Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4204 - acc: 0.9159\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.3100 - acc: 0.9546 - val_loss: 0.4498 - val_acc: 0.9159\n",
            "Learning rate:  0.0001\n",
            "Epoch 91/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.3011 - acc: 0.9575Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4568 - acc: 0.9139\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.3011 - acc: 0.9575 - val_loss: 0.4538 - val_acc: 0.9139\n",
            "Learning rate:  0.0001\n",
            "Epoch 92/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.2930 - acc: 0.9597Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4160 - acc: 0.9162\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2931 - acc: 0.9597 - val_loss: 0.4504 - val_acc: 0.9162\n",
            "Learning rate:  0.0001\n",
            "Epoch 93/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2895 - acc: 0.9603Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.3964 - acc: 0.9143\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2895 - acc: 0.9603 - val_loss: 0.4507 - val_acc: 0.9143\n",
            "Learning rate:  0.0001\n",
            "Epoch 94/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2835 - acc: 0.9613Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.3773 - acc: 0.9135\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2835 - acc: 0.9613 - val_loss: 0.4558 - val_acc: 0.9135\n",
            "Learning rate:  0.0001\n",
            "Epoch 95/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.9615Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4166 - acc: 0.9144\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2801 - acc: 0.9614 - val_loss: 0.4456 - val_acc: 0.9144\n",
            "Learning rate:  0.0001\n",
            "Epoch 96/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2743 - acc: 0.9632Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 203us/sample - loss: 0.4064 - acc: 0.9122\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2743 - acc: 0.9632 - val_loss: 0.4579 - val_acc: 0.9122\n",
            "Learning rate:  0.0001\n",
            "Epoch 97/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2699 - acc: 0.9640Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.3886 - acc: 0.9151\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2699 - acc: 0.9640 - val_loss: 0.4525 - val_acc: 0.9151\n",
            "Learning rate:  0.0001\n",
            "Epoch 98/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.2660 - acc: 0.9637Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4194 - acc: 0.9096\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2660 - acc: 0.9637 - val_loss: 0.4605 - val_acc: 0.9096\n",
            "Learning rate:  0.0001\n",
            "Epoch 99/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2605 - acc: 0.9663Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4856 - acc: 0.9139\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2604 - acc: 0.9663 - val_loss: 0.4600 - val_acc: 0.9139\n",
            "Learning rate:  0.0001\n",
            "Epoch 100/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9661Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4485 - acc: 0.9138\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2584 - acc: 0.9661 - val_loss: 0.4458 - val_acc: 0.9138\n",
            "Learning rate:  0.0001\n",
            "Epoch 101/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2535 - acc: 0.9664Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 188us/sample - loss: 0.4628 - acc: 0.9143\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2534 - acc: 0.9664 - val_loss: 0.4470 - val_acc: 0.9143\n",
            "Learning rate:  0.0001\n",
            "Epoch 102/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2510 - acc: 0.9670Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.5003 - acc: 0.9149\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2510 - acc: 0.9670 - val_loss: 0.4415 - val_acc: 0.9149\n",
            "Learning rate:  0.0001\n",
            "Epoch 103/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2495 - acc: 0.9668Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.5256 - acc: 0.9122\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2495 - acc: 0.9668 - val_loss: 0.4646 - val_acc: 0.9122\n",
            "Learning rate:  0.0001\n",
            "Epoch 104/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2424 - acc: 0.9701Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.5110 - acc: 0.9136\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2424 - acc: 0.9701 - val_loss: 0.4483 - val_acc: 0.9136\n",
            "Learning rate:  0.0001\n",
            "Epoch 105/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.2408 - acc: 0.9692Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.4330 - acc: 0.9129\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2409 - acc: 0.9692 - val_loss: 0.4452 - val_acc: 0.9129\n",
            "Learning rate:  0.0001\n",
            "Epoch 106/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2405 - acc: 0.9678Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4485 - acc: 0.9116\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2405 - acc: 0.9678 - val_loss: 0.4508 - val_acc: 0.9116\n",
            "Learning rate:  0.0001\n",
            "Epoch 107/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2368 - acc: 0.9696Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4529 - acc: 0.9141\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2368 - acc: 0.9696 - val_loss: 0.4533 - val_acc: 0.9141\n",
            "Learning rate:  0.0001\n",
            "Epoch 108/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.2319 - acc: 0.9698Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4923 - acc: 0.9123\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2318 - acc: 0.9698 - val_loss: 0.4582 - val_acc: 0.9123\n",
            "Learning rate:  0.0001\n",
            "Epoch 109/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2308 - acc: 0.9698Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4730 - acc: 0.9104\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2307 - acc: 0.9698 - val_loss: 0.4502 - val_acc: 0.9104\n",
            "Learning rate:  0.0001\n",
            "Epoch 110/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9699Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.5010 - acc: 0.9124\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2292 - acc: 0.9699 - val_loss: 0.4525 - val_acc: 0.9124\n",
            "Learning rate:  0.0001\n",
            "Epoch 111/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9712Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4378 - acc: 0.9143\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2251 - acc: 0.9712 - val_loss: 0.4384 - val_acc: 0.9143\n",
            "Learning rate:  0.0001\n",
            "Epoch 112/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2219 - acc: 0.9720Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 199us/sample - loss: 0.4617 - acc: 0.9117\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2219 - acc: 0.9720 - val_loss: 0.4397 - val_acc: 0.9117\n",
            "Learning rate:  0.0001\n",
            "Epoch 113/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.2207 - acc: 0.9724Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.5625 - acc: 0.9104\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2206 - acc: 0.9725 - val_loss: 0.4495 - val_acc: 0.9104\n",
            "Learning rate:  0.0001\n",
            "Epoch 114/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9722Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.5085 - acc: 0.9102\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2174 - acc: 0.9721 - val_loss: 0.4580 - val_acc: 0.9102\n",
            "Learning rate:  0.0001\n",
            "Epoch 115/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9732Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4766 - acc: 0.9103\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2148 - acc: 0.9732 - val_loss: 0.4569 - val_acc: 0.9103\n",
            "Learning rate:  0.0001\n",
            "Epoch 116/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9730Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 204us/sample - loss: 0.5080 - acc: 0.9083\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.2130 - acc: 0.9730 - val_loss: 0.4671 - val_acc: 0.9083\n",
            "Learning rate:  0.0001\n",
            "Epoch 117/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9726Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 197us/sample - loss: 0.5457 - acc: 0.9096\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.2124 - acc: 0.9726 - val_loss: 0.4556 - val_acc: 0.9096\n",
            "Learning rate:  0.0001\n",
            "Epoch 118/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9741Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4999 - acc: 0.9083\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2086 - acc: 0.9741 - val_loss: 0.4548 - val_acc: 0.9083\n",
            "Learning rate:  0.0001\n",
            "Epoch 119/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9742Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4522 - acc: 0.9096\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.2067 - acc: 0.9743 - val_loss: 0.4491 - val_acc: 0.9096\n",
            "Learning rate:  0.0001\n",
            "Epoch 120/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.2068 - acc: 0.9735Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4941 - acc: 0.9137\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2068 - acc: 0.9735 - val_loss: 0.4429 - val_acc: 0.9137\n",
            "Learning rate:  0.0001\n",
            "Epoch 121/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9734Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4479 - acc: 0.9152\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.2069 - acc: 0.9734 - val_loss: 0.4389 - val_acc: 0.9152\n",
            "Learning rate:  1e-05\n",
            "Epoch 122/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9777Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 187us/sample - loss: 0.4618 - acc: 0.9172\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1943 - acc: 0.9778 - val_loss: 0.4350 - val_acc: 0.9172\n",
            "Learning rate:  1e-05\n",
            "Epoch 123/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9804Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 205us/sample - loss: 0.4729 - acc: 0.9167\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 40s 26ms/step - loss: 0.1894 - acc: 0.9804 - val_loss: 0.4332 - val_acc: 0.9167\n",
            "Learning rate:  1e-05\n",
            "Epoch 124/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9807Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 197us/sample - loss: 0.4746 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 40s 26ms/step - loss: 0.1885 - acc: 0.9807 - val_loss: 0.4334 - val_acc: 0.9169\n",
            "Learning rate:  1e-05\n",
            "Epoch 125/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1891 - acc: 0.9798Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 197us/sample - loss: 0.4569 - acc: 0.9168\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 40s 26ms/step - loss: 0.1890 - acc: 0.9799 - val_loss: 0.4327 - val_acc: 0.9168\n",
            "Learning rate:  1e-05\n",
            "Epoch 126/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9807Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4553 - acc: 0.9161\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1871 - acc: 0.9807 - val_loss: 0.4328 - val_acc: 0.9161\n",
            "Learning rate:  1e-05\n",
            "Epoch 127/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9809Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 200us/sample - loss: 0.4569 - acc: 0.9172\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.1863 - acc: 0.9809 - val_loss: 0.4322 - val_acc: 0.9172\n",
            "Learning rate:  1e-05\n",
            "Epoch 128/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1826 - acc: 0.9823Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 198us/sample - loss: 0.4681 - acc: 0.9172\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 41s 26ms/step - loss: 0.1826 - acc: 0.9823 - val_loss: 0.4312 - val_acc: 0.9172\n",
            "Learning rate:  1e-05\n",
            "Epoch 129/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9813Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.4529 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 39s 25ms/step - loss: 0.1836 - acc: 0.9813 - val_loss: 0.4311 - val_acc: 0.9169\n",
            "Learning rate:  1e-05\n",
            "Epoch 130/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9821Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4495 - acc: 0.9158\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 40s 26ms/step - loss: 0.1838 - acc: 0.9821 - val_loss: 0.4334 - val_acc: 0.9158\n",
            "Learning rate:  1e-05\n",
            "Epoch 131/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1826 - acc: 0.9816Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.4525 - acc: 0.9164\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1827 - acc: 0.9816 - val_loss: 0.4324 - val_acc: 0.9164\n",
            "Learning rate:  1e-05\n",
            "Epoch 132/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9819Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4436 - acc: 0.9157\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1830 - acc: 0.9819 - val_loss: 0.4377 - val_acc: 0.9157\n",
            "Learning rate:  1e-05\n",
            "Epoch 133/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9817Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.4608 - acc: 0.9164\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1834 - acc: 0.9817 - val_loss: 0.4339 - val_acc: 0.9164\n",
            "Learning rate:  1e-05\n",
            "Epoch 134/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9831Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 206us/sample - loss: 0.4421 - acc: 0.9159\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1811 - acc: 0.9831 - val_loss: 0.4357 - val_acc: 0.9159\n",
            "Learning rate:  1e-05\n",
            "Epoch 135/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9829Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.4495 - acc: 0.9161\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1798 - acc: 0.9829 - val_loss: 0.4380 - val_acc: 0.9161\n",
            "Learning rate:  1e-05\n",
            "Epoch 136/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9817Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 187us/sample - loss: 0.4341 - acc: 0.9156\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1819 - acc: 0.9817 - val_loss: 0.4342 - val_acc: 0.9156\n",
            "Learning rate:  1e-05\n",
            "Epoch 137/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9828Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 200us/sample - loss: 0.4450 - acc: 0.9167\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1802 - acc: 0.9828 - val_loss: 0.4369 - val_acc: 0.9167\n",
            "Learning rate:  1e-05\n",
            "Epoch 138/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9824Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4456 - acc: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1810 - acc: 0.9824 - val_loss: 0.4360 - val_acc: 0.9174\n",
            "Learning rate:  1e-05\n",
            "Epoch 139/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9823Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4359 - acc: 0.9178\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1808 - acc: 0.9823 - val_loss: 0.4336 - val_acc: 0.9178\n",
            "Learning rate:  1e-05\n",
            "Epoch 140/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9830Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 188us/sample - loss: 0.4291 - acc: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1789 - acc: 0.9830 - val_loss: 0.4347 - val_acc: 0.9174\n",
            "Learning rate:  1e-05\n",
            "Epoch 141/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9824Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 188us/sample - loss: 0.4325 - acc: 0.9167\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1805 - acc: 0.9824 - val_loss: 0.4324 - val_acc: 0.9167\n",
            "Learning rate:  1e-05\n",
            "Epoch 142/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9835Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 207us/sample - loss: 0.4299 - acc: 0.9156\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1762 - acc: 0.9835 - val_loss: 0.4369 - val_acc: 0.9156\n",
            "Learning rate:  1e-05\n",
            "Epoch 143/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9841Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4342 - acc: 0.9162\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1753 - acc: 0.9841 - val_loss: 0.4341 - val_acc: 0.9162\n",
            "Learning rate:  1e-05\n",
            "Epoch 144/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9835Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4140 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1768 - acc: 0.9835 - val_loss: 0.4351 - val_acc: 0.9169\n",
            "Learning rate:  1e-05\n",
            "Epoch 145/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9833Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 196us/sample - loss: 0.4333 - acc: 0.9161\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1784 - acc: 0.9833 - val_loss: 0.4390 - val_acc: 0.9161\n",
            "Learning rate:  1e-05\n",
            "Epoch 146/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1771 - acc: 0.9827Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4307 - acc: 0.9163\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1772 - acc: 0.9827 - val_loss: 0.4373 - val_acc: 0.9163\n",
            "Learning rate:  1e-05\n",
            "Epoch 147/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9831Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4354 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1769 - acc: 0.9831 - val_loss: 0.4349 - val_acc: 0.9169\n",
            "Learning rate:  1e-05\n",
            "Epoch 148/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9846Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4294 - acc: 0.9168\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1745 - acc: 0.9846 - val_loss: 0.4332 - val_acc: 0.9168\n",
            "Learning rate:  1e-05\n",
            "Epoch 149/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9831Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4302 - acc: 0.9170\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1755 - acc: 0.9831 - val_loss: 0.4328 - val_acc: 0.9170\n",
            "Learning rate:  1e-05\n",
            "Epoch 150/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9831Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 205us/sample - loss: 0.4412 - acc: 0.9159\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1758 - acc: 0.9831 - val_loss: 0.4361 - val_acc: 0.9159\n",
            "Learning rate:  1e-05\n",
            "Epoch 151/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9844Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4285 - acc: 0.9173\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1733 - acc: 0.9845 - val_loss: 0.4367 - val_acc: 0.9173\n",
            "Learning rate:  1e-05\n",
            "Epoch 152/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9834Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4191 - acc: 0.9172\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1750 - acc: 0.9833 - val_loss: 0.4356 - val_acc: 0.9172\n",
            "Learning rate:  1e-05\n",
            "Epoch 153/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9848Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 197us/sample - loss: 0.4393 - acc: 0.9164\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1731 - acc: 0.9848 - val_loss: 0.4392 - val_acc: 0.9164\n",
            "Learning rate:  1e-05\n",
            "Epoch 154/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9832Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.4479 - acc: 0.9172\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1745 - acc: 0.9832 - val_loss: 0.4362 - val_acc: 0.9172\n",
            "Learning rate:  1e-05\n",
            "Epoch 155/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9843Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4423 - acc: 0.9171\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1730 - acc: 0.9843 - val_loss: 0.4360 - val_acc: 0.9171\n",
            "Learning rate:  1e-05\n",
            "Epoch 156/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9831Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4320 - acc: 0.9187\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1744 - acc: 0.9831 - val_loss: 0.4323 - val_acc: 0.9187\n",
            "Learning rate:  1e-05\n",
            "Epoch 157/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9837Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4408 - acc: 0.9172\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1737 - acc: 0.9837 - val_loss: 0.4350 - val_acc: 0.9172\n",
            "Learning rate:  1e-05\n",
            "Epoch 158/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9842Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 206us/sample - loss: 0.4469 - acc: 0.9182\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1721 - acc: 0.9842 - val_loss: 0.4357 - val_acc: 0.9182\n",
            "Learning rate:  1e-05\n",
            "Epoch 159/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9836Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 195us/sample - loss: 0.4386 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1734 - acc: 0.9836 - val_loss: 0.4344 - val_acc: 0.9169\n",
            "Learning rate:  1e-05\n",
            "Epoch 160/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9845Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4716 - acc: 0.9176\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1708 - acc: 0.9845 - val_loss: 0.4363 - val_acc: 0.9176\n",
            "Learning rate:  1e-05\n",
            "Epoch 161/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9838Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 196us/sample - loss: 0.4732 - acc: 0.9178\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1731 - acc: 0.9838 - val_loss: 0.4371 - val_acc: 0.9178\n",
            "Learning rate:  1e-06\n",
            "Epoch 162/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9850Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4681 - acc: 0.9177\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1693 - acc: 0.9850 - val_loss: 0.4341 - val_acc: 0.9177\n",
            "Learning rate:  1e-06\n",
            "Epoch 163/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9847Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4709 - acc: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1705 - acc: 0.9848 - val_loss: 0.4354 - val_acc: 0.9174\n",
            "Learning rate:  1e-06\n",
            "Epoch 164/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9840Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4600 - acc: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1714 - acc: 0.9840 - val_loss: 0.4334 - val_acc: 0.9174\n",
            "Learning rate:  1e-06\n",
            "Epoch 165/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9849Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4530 - acc: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1694 - acc: 0.9848 - val_loss: 0.4329 - val_acc: 0.9174\n",
            "Learning rate:  1e-06\n",
            "Epoch 166/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9843Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 204us/sample - loss: 0.4605 - acc: 0.9180\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1702 - acc: 0.9843 - val_loss: 0.4336 - val_acc: 0.9180\n",
            "Learning rate:  1e-06\n",
            "Epoch 167/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9838Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4626 - acc: 0.9175\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1722 - acc: 0.9838 - val_loss: 0.4335 - val_acc: 0.9175\n",
            "Learning rate:  1e-06\n",
            "Epoch 168/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9849Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4508 - acc: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1696 - acc: 0.9849 - val_loss: 0.4344 - val_acc: 0.9174\n",
            "Learning rate:  1e-06\n",
            "Epoch 169/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9848Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 197us/sample - loss: 0.4582 - acc: 0.9168\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1708 - acc: 0.9848 - val_loss: 0.4341 - val_acc: 0.9168\n",
            "Learning rate:  1e-06\n",
            "Epoch 170/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9849Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4573 - acc: 0.9176\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1696 - acc: 0.9850 - val_loss: 0.4351 - val_acc: 0.9176\n",
            "Learning rate:  1e-06\n",
            "Epoch 171/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9844Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4630 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1710 - acc: 0.9843 - val_loss: 0.4344 - val_acc: 0.9169\n",
            "Learning rate:  1e-06\n",
            "Epoch 172/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9846Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 188us/sample - loss: 0.4563 - acc: 0.9171\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1703 - acc: 0.9846 - val_loss: 0.4350 - val_acc: 0.9171\n",
            "Learning rate:  1e-06\n",
            "Epoch 173/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9848Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4549 - acc: 0.9172\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1701 - acc: 0.9848 - val_loss: 0.4357 - val_acc: 0.9172\n",
            "Learning rate:  1e-06\n",
            "Epoch 174/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9848Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 208us/sample - loss: 0.4561 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1693 - acc: 0.9848 - val_loss: 0.4356 - val_acc: 0.9169\n",
            "Learning rate:  1e-06\n",
            "Epoch 175/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9851Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4468 - acc: 0.9165\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1681 - acc: 0.9851 - val_loss: 0.4341 - val_acc: 0.9165\n",
            "Learning rate:  1e-06\n",
            "Epoch 176/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9849Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4543 - acc: 0.9168\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1701 - acc: 0.9849 - val_loss: 0.4369 - val_acc: 0.9168\n",
            "Learning rate:  1e-06\n",
            "Epoch 177/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9844Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 198us/sample - loss: 0.4552 - acc: 0.9172\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1703 - acc: 0.9844 - val_loss: 0.4346 - val_acc: 0.9172\n",
            "Learning rate:  1e-06\n",
            "Epoch 178/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9853Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 192us/sample - loss: 0.4437 - acc: 0.9170\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1694 - acc: 0.9853 - val_loss: 0.4349 - val_acc: 0.9170\n",
            "Learning rate:  1e-06\n",
            "Epoch 179/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1692 - acc: 0.9855Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4408 - acc: 0.9176\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1692 - acc: 0.9855 - val_loss: 0.4336 - val_acc: 0.9176\n",
            "Learning rate:  1e-06\n",
            "Epoch 180/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9843Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 188us/sample - loss: 0.4413 - acc: 0.9177\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1702 - acc: 0.9843 - val_loss: 0.4340 - val_acc: 0.9177\n",
            "Learning rate:  1e-06\n",
            "Epoch 181/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9853Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 188us/sample - loss: 0.4486 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1690 - acc: 0.9852 - val_loss: 0.4355 - val_acc: 0.9169\n",
            "Learning rate:  5e-07\n",
            "Epoch 182/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9855Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 199us/sample - loss: 0.4538 - acc: 0.9176\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1686 - acc: 0.9855 - val_loss: 0.4341 - val_acc: 0.9176\n",
            "Learning rate:  5e-07\n",
            "Epoch 183/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9851Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4451 - acc: 0.9170\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1683 - acc: 0.9851 - val_loss: 0.4353 - val_acc: 0.9170\n",
            "Learning rate:  5e-07\n",
            "Epoch 184/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9853Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4458 - acc: 0.9165\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1701 - acc: 0.9853 - val_loss: 0.4359 - val_acc: 0.9165\n",
            "Learning rate:  5e-07\n",
            "Epoch 185/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1692 - acc: 0.9849Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 206us/sample - loss: 0.4446 - acc: 0.9168\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1693 - acc: 0.9849 - val_loss: 0.4341 - val_acc: 0.9168\n",
            "Learning rate:  5e-07\n",
            "Epoch 186/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9841Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 194us/sample - loss: 0.4483 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1707 - acc: 0.9842 - val_loss: 0.4347 - val_acc: 0.9169\n",
            "Learning rate:  5e-07\n",
            "Epoch 187/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9856Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 201us/sample - loss: 0.4527 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 25ms/step - loss: 0.1681 - acc: 0.9856 - val_loss: 0.4352 - val_acc: 0.9169\n",
            "Learning rate:  5e-07\n",
            "Epoch 188/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9862Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4391 - acc: 0.9165\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1674 - acc: 0.9862 - val_loss: 0.4340 - val_acc: 0.9165\n",
            "Learning rate:  5e-07\n",
            "Epoch 189/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9854Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4504 - acc: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1695 - acc: 0.9853 - val_loss: 0.4350 - val_acc: 0.9174\n",
            "Learning rate:  5e-07\n",
            "Epoch 190/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9845Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4474 - acc: 0.9173\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1702 - acc: 0.9845 - val_loss: 0.4343 - val_acc: 0.9173\n",
            "Learning rate:  5e-07\n",
            "Epoch 191/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9859Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 201us/sample - loss: 0.4532 - acc: 0.9175\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1685 - acc: 0.9859 - val_loss: 0.4343 - val_acc: 0.9175\n",
            "Learning rate:  5e-07\n",
            "Epoch 192/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1692 - acc: 0.9851Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4497 - acc: 0.9180\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1692 - acc: 0.9851 - val_loss: 0.4345 - val_acc: 0.9180\n",
            "Learning rate:  5e-07\n",
            "Epoch 193/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9852Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4458 - acc: 0.9177\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1693 - acc: 0.9853 - val_loss: 0.4346 - val_acc: 0.9177\n",
            "Learning rate:  5e-07\n",
            "Epoch 194/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9852Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 189us/sample - loss: 0.4493 - acc: 0.9173\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1694 - acc: 0.9852 - val_loss: 0.4343 - val_acc: 0.9173\n",
            "Learning rate:  5e-07\n",
            "Epoch 195/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1695 - acc: 0.9847Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4381 - acc: 0.9169\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1696 - acc: 0.9847 - val_loss: 0.4332 - val_acc: 0.9169\n",
            "Learning rate:  5e-07\n",
            "Epoch 196/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9854Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 191us/sample - loss: 0.4535 - acc: 0.9173\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1690 - acc: 0.9854 - val_loss: 0.4363 - val_acc: 0.9173\n",
            "Learning rate:  5e-07\n",
            "Epoch 197/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9842Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 193us/sample - loss: 0.4430 - acc: 0.9171\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1706 - acc: 0.9842 - val_loss: 0.4354 - val_acc: 0.9171\n",
            "Learning rate:  5e-07\n",
            "Epoch 198/200\n",
            "1560/1562 [============================>.] - ETA: 0s - loss: 0.1692 - acc: 0.9855Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 190us/sample - loss: 0.4470 - acc: 0.9170\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1692 - acc: 0.9855 - val_loss: 0.4352 - val_acc: 0.9170\n",
            "Learning rate:  5e-07\n",
            "Epoch 199/200\n",
            "1559/1562 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9852Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 202us/sample - loss: 0.4522 - acc: 0.9174\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 37s 24ms/step - loss: 0.1698 - acc: 0.9852 - val_loss: 0.4344 - val_acc: 0.9174\n",
            "Learning rate:  5e-07\n",
            "Epoch 200/200\n",
            "1561/1562 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9853Epoch 1/200\n",
            "10000/1562 [================================================================================================================================================================================================] - 2s 188us/sample - loss: 0.4411 - acc: 0.9177\n",
            "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
            "1562/1562 [==============================] - 38s 24ms/step - loss: 0.1681 - acc: 0.9853 - val_loss: 0.4348 - val_acc: 0.9177\n",
            "Test loss: 0.43473487532138827\n",
            "Test accuracy: 0.9177\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}